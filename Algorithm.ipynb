{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "import random \n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Store</th>\n",
       "      <th>Week</th>\n",
       "      <th>F1</th>\n",
       "      <th>D1</th>\n",
       "      <th>PR1</th>\n",
       "      <th>P1</th>\n",
       "      <th>F2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PR2</th>\n",
       "      <th>...</th>\n",
       "      <th>Y19</th>\n",
       "      <th>Y20</th>\n",
       "      <th>Y21</th>\n",
       "      <th>Y22</th>\n",
       "      <th>Y23</th>\n",
       "      <th>Y24</th>\n",
       "      <th>Random</th>\n",
       "      <th>SoupSeasonality</th>\n",
       "      <th>YogurtSeasonality</th>\n",
       "      <th>BeerSeasonality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278</td>\n",
       "      <td>232633</td>\n",
       "      <td>1114</td>\n",
       "      <td>0.565621</td>\n",
       "      <td>0.715097</td>\n",
       "      <td>0.674420</td>\n",
       "      <td>3.594764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083157</td>\n",
       "      <td>...</td>\n",
       "      <td>2469.5461</td>\n",
       "      <td>572.870</td>\n",
       "      <td>7247</td>\n",
       "      <td>84.9106</td>\n",
       "      <td>1313.075</td>\n",
       "      <td>420.0171</td>\n",
       "      <td>Test</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>232633</td>\n",
       "      <td>1115</td>\n",
       "      <td>0.523705</td>\n",
       "      <td>0.714970</td>\n",
       "      <td>0.589934</td>\n",
       "      <td>3.589033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081281</td>\n",
       "      <td>...</td>\n",
       "      <td>2373.2827</td>\n",
       "      <td>505.807</td>\n",
       "      <td>9396</td>\n",
       "      <td>115.7419</td>\n",
       "      <td>1264.700</td>\n",
       "      <td>542.4662</td>\n",
       "      <td>Train</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>232633</td>\n",
       "      <td>1116</td>\n",
       "      <td>0.499391</td>\n",
       "      <td>0.681167</td>\n",
       "      <td>0.685569</td>\n",
       "      <td>3.183856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089665</td>\n",
       "      <td>...</td>\n",
       "      <td>1945.1934</td>\n",
       "      <td>555.621</td>\n",
       "      <td>7338</td>\n",
       "      <td>86.5451</td>\n",
       "      <td>1562.100</td>\n",
       "      <td>543.9062</td>\n",
       "      <td>Train</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240</td>\n",
       "      <td>232633</td>\n",
       "      <td>1117</td>\n",
       "      <td>0.582240</td>\n",
       "      <td>0.736953</td>\n",
       "      <td>0.777993</td>\n",
       "      <td>3.357538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085037</td>\n",
       "      <td>...</td>\n",
       "      <td>1841.9563</td>\n",
       "      <td>551.320</td>\n",
       "      <td>8113</td>\n",
       "      <td>84.5918</td>\n",
       "      <td>1564.725</td>\n",
       "      <td>806.6924</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>215</td>\n",
       "      <td>232633</td>\n",
       "      <td>1118</td>\n",
       "      <td>0.336871</td>\n",
       "      <td>0.656440</td>\n",
       "      <td>0.504925</td>\n",
       "      <td>3.764616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081152</td>\n",
       "      <td>...</td>\n",
       "      <td>1824.3048</td>\n",
       "      <td>574.784</td>\n",
       "      <td>10730</td>\n",
       "      <td>103.5890</td>\n",
       "      <td>1251.775</td>\n",
       "      <td>474.7744</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Store  Week        F1        D1       PR1        P1   F2   D2  \\\n",
       "0         278  232633  1114  0.565621  0.715097  0.674420  3.594764  0.0  0.0   \n",
       "1          49  232633  1115  0.523705  0.714970  0.589934  3.589033  0.0  0.0   \n",
       "2          18  232633  1116  0.499391  0.681167  0.685569  3.183856  0.0  0.0   \n",
       "3         240  232633  1117  0.582240  0.736953  0.777993  3.357538  0.0  0.0   \n",
       "4         215  232633  1118  0.336871  0.656440  0.504925  3.764616  0.0  0.0   \n",
       "\n",
       "        PR2       ...               Y19      Y20    Y21       Y22       Y23  \\\n",
       "0  0.083157       ...         2469.5461  572.870   7247   84.9106  1313.075   \n",
       "1  0.081281       ...         2373.2827  505.807   9396  115.7419  1264.700   \n",
       "2  0.089665       ...         1945.1934  555.621   7338   86.5451  1562.100   \n",
       "3  0.085037       ...         1841.9563  551.320   8113   84.5918  1564.725   \n",
       "4  0.081152       ...         1824.3048  574.784  10730  103.5890  1251.775   \n",
       "\n",
       "        Y24  Random  SoupSeasonality  YogurtSeasonality  BeerSeasonality  \n",
       "0  420.0171    Test                2                  1                0  \n",
       "1  542.4662   Train                2                  1                1  \n",
       "2  543.9062   Train                2                  1                1  \n",
       "3  806.6924   Train                1                  1                1  \n",
       "4  474.7744   Train                1                  1                0  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data, store 1, with seasonality\n",
    "store1 = pd.read_csv('Store1_season.csv')\n",
    "store1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = store1[store1.Random == 'Train']\n",
    "test = store1[store1.Random != 'Train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>D1</th>\n",
       "      <th>PR1</th>\n",
       "      <th>P1</th>\n",
       "      <th>F2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PR2</th>\n",
       "      <th>P2</th>\n",
       "      <th>F3</th>\n",
       "      <th>D3</th>\n",
       "      <th>...</th>\n",
       "      <th>Y18</th>\n",
       "      <th>Y19</th>\n",
       "      <th>Y20</th>\n",
       "      <th>Y21</th>\n",
       "      <th>Y22</th>\n",
       "      <th>Y23</th>\n",
       "      <th>Y24</th>\n",
       "      <th>SoupSeasonality</th>\n",
       "      <th>YogurtSeasonality</th>\n",
       "      <th>BeerSeasonality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.523705</td>\n",
       "      <td>0.714970</td>\n",
       "      <td>0.589934</td>\n",
       "      <td>3.589033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081281</td>\n",
       "      <td>32.728396</td>\n",
       "      <td>0.088096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6356.1697</td>\n",
       "      <td>2373.2827</td>\n",
       "      <td>505.807</td>\n",
       "      <td>9396</td>\n",
       "      <td>115.7419</td>\n",
       "      <td>1264.700</td>\n",
       "      <td>542.4662</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.499391</td>\n",
       "      <td>0.681167</td>\n",
       "      <td>0.685569</td>\n",
       "      <td>3.183856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089665</td>\n",
       "      <td>32.550162</td>\n",
       "      <td>0.060542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5228.9130</td>\n",
       "      <td>1945.1934</td>\n",
       "      <td>555.621</td>\n",
       "      <td>7338</td>\n",
       "      <td>86.5451</td>\n",
       "      <td>1562.100</td>\n",
       "      <td>543.9062</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.582240</td>\n",
       "      <td>0.736953</td>\n",
       "      <td>0.777993</td>\n",
       "      <td>3.357538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085037</td>\n",
       "      <td>32.653651</td>\n",
       "      <td>0.596178</td>\n",
       "      <td>0.479989</td>\n",
       "      <td>...</td>\n",
       "      <td>3546.9937</td>\n",
       "      <td>1841.9563</td>\n",
       "      <td>551.320</td>\n",
       "      <td>8113</td>\n",
       "      <td>84.5918</td>\n",
       "      <td>1564.725</td>\n",
       "      <td>806.6924</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.336871</td>\n",
       "      <td>0.656440</td>\n",
       "      <td>0.504925</td>\n",
       "      <td>3.764616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081152</td>\n",
       "      <td>32.562304</td>\n",
       "      <td>0.484867</td>\n",
       "      <td>0.368219</td>\n",
       "      <td>...</td>\n",
       "      <td>4268.0918</td>\n",
       "      <td>1824.3048</td>\n",
       "      <td>574.784</td>\n",
       "      <td>10730</td>\n",
       "      <td>103.5890</td>\n",
       "      <td>1251.775</td>\n",
       "      <td>474.7744</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.513508</td>\n",
       "      <td>0.771890</td>\n",
       "      <td>0.481677</td>\n",
       "      <td>3.623867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011132</td>\n",
       "      <td>32.631095</td>\n",
       "      <td>0.507620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3642.9938</td>\n",
       "      <td>2338.4283</td>\n",
       "      <td>503.840</td>\n",
       "      <td>7744</td>\n",
       "      <td>80.5570</td>\n",
       "      <td>1358.125</td>\n",
       "      <td>624.9783</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         F1        D1       PR1        P1   F2   D2       PR2         P2  \\\n",
       "1  0.523705  0.714970  0.589934  3.589033  0.0  0.0  0.081281  32.728396   \n",
       "2  0.499391  0.681167  0.685569  3.183856  0.0  0.0  0.089665  32.550162   \n",
       "3  0.582240  0.736953  0.777993  3.357538  0.0  0.0  0.085037  32.653651   \n",
       "4  0.336871  0.656440  0.504925  3.764616  0.0  0.0  0.081152  32.562304   \n",
       "6  0.513508  0.771890  0.481677  3.623867  0.0  0.0  0.011132  32.631095   \n",
       "\n",
       "         F3        D3       ...               Y18        Y19      Y20    Y21  \\\n",
       "1  0.088096  0.000000       ...         6356.1697  2373.2827  505.807   9396   \n",
       "2  0.060542  0.000000       ...         5228.9130  1945.1934  555.621   7338   \n",
       "3  0.596178  0.479989       ...         3546.9937  1841.9563  551.320   8113   \n",
       "4  0.484867  0.368219       ...         4268.0918  1824.3048  574.784  10730   \n",
       "6  0.507620  0.000000       ...         3642.9938  2338.4283  503.840   7744   \n",
       "\n",
       "        Y22       Y23       Y24  SoupSeasonality  YogurtSeasonality  \\\n",
       "1  115.7419  1264.700  542.4662                2                  1   \n",
       "2   86.5451  1562.100  543.9062                2                  1   \n",
       "3   84.5918  1564.725  806.6924                1                  1   \n",
       "4  103.5890  1251.775  474.7744                1                  1   \n",
       "6   80.5570  1358.125  624.9783                1                  1   \n",
       "\n",
       "   BeerSeasonality  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                0  \n",
       "6                1  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set\n",
    "cols = ['F1', 'D1','PR1','P1','F2', 'D2','PR2','P2', 'F3', 'D3','PR3','P3', 'F4', 'D4','PR4','P4', 'F5', 'D5','PR5','P5', 'F6', 'D6','PR6','P6', 'F7', 'D7','PR7','P7', 'F8', 'D8','PR8','P8', 'F9', 'D9','PR9','P9','F10', 'D10','PR10','P10', 'F11', 'D11','PR11','P11', 'F12', 'D12','PR12','P12', 'F13', 'D13','PR13','P13','F14', 'D14','PR14','P14', 'F15', 'D15','PR15','P15', 'F16', 'D16','PR16','P16', 'F17', 'D17','PR17','P17', 'F18', 'D18','PR18','P18', 'F19', 'D19','PR19','P19', 'F20', 'D20','PR20','P20', 'F21', 'D21','PR21','P21', 'F22', 'D22','PR22','P22', 'F23', 'D23','PR23','P23', 'F24', 'D24','PR24','P24', 'Y1','Y2','Y3','Y4','Y5','Y6','Y7','Y8','Y9', 'Y10','Y11','Y12','Y13','Y14','Y15','Y16','Y17','Y18', 'Y19','Y20','Y21','Y22','Y23','Y24','SoupSeasonality','YogurtSeasonality','BeerSeasonality']\n",
    "train = train.loc[:,cols]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>D1</th>\n",
       "      <th>PR1</th>\n",
       "      <th>P1</th>\n",
       "      <th>F2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PR2</th>\n",
       "      <th>P2</th>\n",
       "      <th>F3</th>\n",
       "      <th>D3</th>\n",
       "      <th>...</th>\n",
       "      <th>Y18</th>\n",
       "      <th>Y19</th>\n",
       "      <th>Y20</th>\n",
       "      <th>Y21</th>\n",
       "      <th>Y22</th>\n",
       "      <th>Y23</th>\n",
       "      <th>Y24</th>\n",
       "      <th>SoupSeasonality</th>\n",
       "      <th>YogurtSeasonality</th>\n",
       "      <th>BeerSeasonality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.565621</td>\n",
       "      <td>0.715097</td>\n",
       "      <td>0.674420</td>\n",
       "      <td>3.594764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083157</td>\n",
       "      <td>32.399747</td>\n",
       "      <td>0.402274</td>\n",
       "      <td>0.380457</td>\n",
       "      <td>...</td>\n",
       "      <td>5207.0689</td>\n",
       "      <td>2469.5461</td>\n",
       "      <td>572.870</td>\n",
       "      <td>7247</td>\n",
       "      <td>84.9106</td>\n",
       "      <td>1313.075</td>\n",
       "      <td>420.0171</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.485297</td>\n",
       "      <td>0.709264</td>\n",
       "      <td>0.611687</td>\n",
       "      <td>3.424422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088546</td>\n",
       "      <td>32.594110</td>\n",
       "      <td>0.406357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3444.8374</td>\n",
       "      <td>1694.2602</td>\n",
       "      <td>535.807</td>\n",
       "      <td>9618</td>\n",
       "      <td>77.2792</td>\n",
       "      <td>1577.475</td>\n",
       "      <td>542.4420</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.484504</td>\n",
       "      <td>0.721262</td>\n",
       "      <td>0.675964</td>\n",
       "      <td>3.534917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.311447</td>\n",
       "      <td>0.479945</td>\n",
       "      <td>0.603150</td>\n",
       "      <td>...</td>\n",
       "      <td>2883.9342</td>\n",
       "      <td>1788.2455</td>\n",
       "      <td>514.864</td>\n",
       "      <td>10485</td>\n",
       "      <td>91.8167</td>\n",
       "      <td>1363.600</td>\n",
       "      <td>748.8265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.546739</td>\n",
       "      <td>0.724376</td>\n",
       "      <td>0.880852</td>\n",
       "      <td>3.291879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.532426</td>\n",
       "      <td>0.319584</td>\n",
       "      <td>0.153036</td>\n",
       "      <td>...</td>\n",
       "      <td>1903.8642</td>\n",
       "      <td>1733.9377</td>\n",
       "      <td>483.994</td>\n",
       "      <td>6056</td>\n",
       "      <td>78.2852</td>\n",
       "      <td>1702.075</td>\n",
       "      <td>806.7878</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.669575</td>\n",
       "      <td>0.723571</td>\n",
       "      <td>0.882006</td>\n",
       "      <td>3.224575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.999735</td>\n",
       "      <td>0.675101</td>\n",
       "      <td>0.686690</td>\n",
       "      <td>...</td>\n",
       "      <td>1956.7309</td>\n",
       "      <td>1246.8926</td>\n",
       "      <td>511.407</td>\n",
       "      <td>9031</td>\n",
       "      <td>68.9788</td>\n",
       "      <td>1402.125</td>\n",
       "      <td>862.1228</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          F1        D1       PR1        P1   F2   D2       PR2         P2  \\\n",
       "0   0.565621  0.715097  0.674420  3.594764  0.0  0.0  0.083157  32.399747   \n",
       "5   0.485297  0.709264  0.611687  3.424422  0.0  0.0  0.088546  32.594110   \n",
       "10  0.484504  0.721262  0.675964  3.534917  0.0  0.0  0.000000  32.311447   \n",
       "12  0.546739  0.724376  0.880852  3.291879  0.0  0.0  0.000000  33.532426   \n",
       "13  0.669575  0.723571  0.882006  3.224575  0.0  0.0  0.000000  33.999735   \n",
       "\n",
       "          F3        D3       ...               Y18        Y19      Y20    Y21  \\\n",
       "0   0.402274  0.380457       ...         5207.0689  2469.5461  572.870   7247   \n",
       "5   0.406357  0.000000       ...         3444.8374  1694.2602  535.807   9618   \n",
       "10  0.479945  0.603150       ...         2883.9342  1788.2455  514.864  10485   \n",
       "12  0.319584  0.153036       ...         1903.8642  1733.9377  483.994   6056   \n",
       "13  0.675101  0.686690       ...         1956.7309  1246.8926  511.407   9031   \n",
       "\n",
       "        Y22       Y23       Y24  SoupSeasonality  YogurtSeasonality  \\\n",
       "0   84.9106  1313.075  420.0171                2                  1   \n",
       "5   77.2792  1577.475  542.4420                1                  1   \n",
       "10  91.8167  1363.600  748.8265                1                  1   \n",
       "12  78.2852  1702.075  806.7878                1                  1   \n",
       "13  68.9788  1402.125  862.1228                1                  1   \n",
       "\n",
       "    BeerSeasonality  \n",
       "0                 0  \n",
       "5                 1  \n",
       "10                1  \n",
       "12                1  \n",
       "13                1  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test set\n",
    "cols = ['F1', 'D1','PR1','P1','F2', 'D2','PR2','P2', 'F3', 'D3','PR3','P3', 'F4', 'D4','PR4','P4', 'F5', 'D5','PR5','P5', 'F6', 'D6','PR6','P6', 'F7', 'D7','PR7','P7', 'F8', 'D8','PR8','P8', 'F9', 'D9','PR9','P9','F10', 'D10','PR10','P10', 'F11', 'D11','PR11','P11', 'F12', 'D12','PR12','P12', 'F13', 'D13','PR13','P13','F14', 'D14','PR14','P14', 'F15', 'D15','PR15','P15', 'F16', 'D16','PR16','P16', 'F17', 'D17','PR17','P17', 'F18', 'D18','PR18','P18', 'F19', 'D19','PR19','P19', 'F20', 'D20','PR20','P20', 'F21', 'D21','PR21','P21', 'F22', 'D22','PR22','P22', 'F23', 'D23','PR23','P23', 'F24', 'D24','PR24','P24', 'Y1','Y2','Y3','Y4','Y5','Y6','Y7','Y8','Y9', 'Y10','Y11','Y12','Y13','Y14','Y15','Y16','Y17','Y18', 'Y19','Y20','Y21','Y22','Y23','Y24','SoupSeasonality','YogurtSeasonality','BeerSeasonality']\n",
    "test = test.loc[:,cols]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use(\"fivethirtyeight\")\n",
    "#Import the dataset and define the feature and target columns#\n",
    "X = train.iloc[:,0:96]\n",
    "y = train.loc[:,'Y1']\n",
    "dataset = pd.concat([X, y], axis = 1, join='outer')\n",
    "mean_data = np.mean(dataset.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>D1</th>\n",
       "      <th>PR1</th>\n",
       "      <th>P1</th>\n",
       "      <th>F2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PR2</th>\n",
       "      <th>P2</th>\n",
       "      <th>F3</th>\n",
       "      <th>D3</th>\n",
       "      <th>...</th>\n",
       "      <th>P22</th>\n",
       "      <th>F23</th>\n",
       "      <th>D23</th>\n",
       "      <th>PR23</th>\n",
       "      <th>P23</th>\n",
       "      <th>F24</th>\n",
       "      <th>D24</th>\n",
       "      <th>PR24</th>\n",
       "      <th>P24</th>\n",
       "      <th>Y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.523705</td>\n",
       "      <td>0.714970</td>\n",
       "      <td>0.589934</td>\n",
       "      <td>3.589033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081281</td>\n",
       "      <td>32.728396</td>\n",
       "      <td>0.088096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.747756</td>\n",
       "      <td>0.166937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.590357</td>\n",
       "      <td>1.543362</td>\n",
       "      <td>0.082033</td>\n",
       "      <td>0.071894</td>\n",
       "      <td>0.391729</td>\n",
       "      <td>15.903184</td>\n",
       "      <td>4457.5098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.499391</td>\n",
       "      <td>0.681167</td>\n",
       "      <td>0.685569</td>\n",
       "      <td>3.183856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089665</td>\n",
       "      <td>32.550162</td>\n",
       "      <td>0.060542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.390423</td>\n",
       "      <td>0.288394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.636323</td>\n",
       "      <td>1.425869</td>\n",
       "      <td>0.296926</td>\n",
       "      <td>0.310715</td>\n",
       "      <td>0.501372</td>\n",
       "      <td>15.319130</td>\n",
       "      <td>5175.7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.582240</td>\n",
       "      <td>0.736953</td>\n",
       "      <td>0.777993</td>\n",
       "      <td>3.357538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085037</td>\n",
       "      <td>32.653651</td>\n",
       "      <td>0.596178</td>\n",
       "      <td>0.479989</td>\n",
       "      <td>...</td>\n",
       "      <td>8.638190</td>\n",
       "      <td>0.524757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.751154</td>\n",
       "      <td>1.335219</td>\n",
       "      <td>0.472609</td>\n",
       "      <td>0.462692</td>\n",
       "      <td>0.570540</td>\n",
       "      <td>15.272562</td>\n",
       "      <td>5954.5051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.336871</td>\n",
       "      <td>0.656440</td>\n",
       "      <td>0.504925</td>\n",
       "      <td>3.764616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081152</td>\n",
       "      <td>32.562304</td>\n",
       "      <td>0.484867</td>\n",
       "      <td>0.368219</td>\n",
       "      <td>...</td>\n",
       "      <td>7.571557</td>\n",
       "      <td>0.282719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452278</td>\n",
       "      <td>1.599185</td>\n",
       "      <td>0.212733</td>\n",
       "      <td>0.212206</td>\n",
       "      <td>0.221052</td>\n",
       "      <td>15.971122</td>\n",
       "      <td>3811.3663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.513508</td>\n",
       "      <td>0.771890</td>\n",
       "      <td>0.481677</td>\n",
       "      <td>3.623867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011132</td>\n",
       "      <td>32.631095</td>\n",
       "      <td>0.507620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.087814</td>\n",
       "      <td>0.507556</td>\n",
       "      <td>0.170087</td>\n",
       "      <td>0.591127</td>\n",
       "      <td>1.570054</td>\n",
       "      <td>0.292410</td>\n",
       "      <td>0.192269</td>\n",
       "      <td>0.456543</td>\n",
       "      <td>15.599054</td>\n",
       "      <td>4431.8269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         F1        D1       PR1        P1   F2   D2       PR2         P2  \\\n",
       "1  0.523705  0.714970  0.589934  3.589033  0.0  0.0  0.081281  32.728396   \n",
       "2  0.499391  0.681167  0.685569  3.183856  0.0  0.0  0.089665  32.550162   \n",
       "3  0.582240  0.736953  0.777993  3.357538  0.0  0.0  0.085037  32.653651   \n",
       "4  0.336871  0.656440  0.504925  3.764616  0.0  0.0  0.081152  32.562304   \n",
       "6  0.513508  0.771890  0.481677  3.623867  0.0  0.0  0.011132  32.631095   \n",
       "\n",
       "         F3        D3    ...           P22       F23       D23      PR23  \\\n",
       "1  0.088096  0.000000    ...      7.747756  0.166937  0.000000  0.590357   \n",
       "2  0.060542  0.000000    ...      8.390423  0.288394  0.000000  0.636323   \n",
       "3  0.596178  0.479989    ...      8.638190  0.524757  0.000000  0.751154   \n",
       "4  0.484867  0.368219    ...      7.571557  0.282719  0.000000  0.452278   \n",
       "6  0.507620  0.000000    ...      8.087814  0.507556  0.170087  0.591127   \n",
       "\n",
       "        P23       F24       D24      PR24        P24         Y1  \n",
       "1  1.543362  0.082033  0.071894  0.391729  15.903184  4457.5098  \n",
       "2  1.425869  0.296926  0.310715  0.501372  15.319130  5175.7999  \n",
       "3  1.335219  0.472609  0.462692  0.570540  15.272562  5954.5051  \n",
       "4  1.599185  0.212733  0.212206  0.221052  15.971122  3811.3663  \n",
       "6  1.570054  0.292410  0.192269  0.456543  15.599054  4431.8269  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the varaince of a dataset\n",
    "This function takes three arguments.\n",
    "1. data = The dataset for whose feature the variance should be calculated\n",
    "2. split_attribute_name = the name of the feature for which the weighted variance should be calculated\n",
    "3. target_name = the name of the target feature.\n",
    "\"\"\"    \n",
    "def var(data,split_attribute_name,target_name=\"Y1\"):\n",
    "    \n",
    "    feature_values = np.unique(data[split_attribute_name])\n",
    "    feature_variance = 0\n",
    "    for value in feature_values:\n",
    "        #Create the data subsets --> Split the original data along the values of the split_attribute_name feature\n",
    "        # and reset the index to not run into an error while using the df.loc[] operation below\n",
    "        subset = data.query('{0} <= {1}'.format(split_attribute_name,value)).reset_index()\n",
    "        #Calculate the weighted variance of each subset            \n",
    "        value_var = (len(subset)/len(data))*np.var(subset[target_name],ddof=1)\n",
    "        \n",
    "        #If value_var = nan, we make it to be 0\n",
    "        value_var = np.nan_to_num(value_var, copy=False)\n",
    "        \n",
    "        #Calculate the weighted variance of the feature\n",
    "        feature_variance+=value_var\n",
    "    return feature_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classification(data,originaldata,features,min_instances,target_attribute_name,parent_node_class = None):\n",
    "    \"\"\"\n",
    "    Classification Algorithm: This function takes the same 5 parameters as the original classification algorithm in the\n",
    "    previous chapter plus one parameter (min_instances) which defines the number of minimal instances\n",
    "    per node as early stopping criterion.\n",
    "    \"\"\"   \n",
    "    #Define the stopping criteria --> If one of this is satisfied, we want to return a leaf node#\n",
    "    \n",
    "    #########This criterion is new########################\n",
    "    #If all target_values have the same value, return the mean value of the target feature for this dataset\n",
    "    if len(data) <= int(min_instances):\n",
    "        return np.mean(data[target_attribute_name])\n",
    "    #######################################################\n",
    "    \n",
    "    #If the dataset is empty, return the mean target feature value in the original dataset\n",
    "    elif len(data)==0:\n",
    "        return np.mean(originaldata[target_attribute_name])\n",
    "    \n",
    "    #If the feature space is empty, return the mean target feature value of the direct parent node --> Note that\n",
    "    #the direct parent node is that node which has called the current run of the algorithm and hence\n",
    "    #the mean target feature value is stored in the parent_node_class variable.\n",
    "    \n",
    "    elif len(features) ==0:\n",
    "        return parent_node_class\n",
    "    \n",
    "    #If none of the above holds true, grow the tree!\n",
    "    \n",
    "    else:\n",
    "        #Set the default value for this node --> The mean target feature value of the current node\n",
    "        parent_node_class = np.mean(data[target_attribute_name])\n",
    "        #Select the feature which best splits the dataset\n",
    "        item_values = [var(data,feature) for feature in features] #Return the variance for features in the dataset\n",
    "        best_feature_index = np.argmin(item_values)\n",
    "        best_feature = features[best_feature_index]\n",
    "        \n",
    "        #Create the tree structure. The root gets the name of the feature (best_feature) with the minimum variance.\n",
    "        tree = {best_feature:{}}\n",
    "        \n",
    "        \n",
    "        #Remove the feature with the lowest variance from the feature space\n",
    "        features = [i for i in features if i != best_feature]\n",
    "        \n",
    "        #Grow a branch under the root node for each possible value of the root node feature\n",
    "        \n",
    "        for value in np.unique(data[best_feature]):\n",
    "            value = value\n",
    "            #Split the dataset along the value of the feature with the lowest variance and therewith create sub_datasets\n",
    "            sub_data = data.where(data[best_feature] < value).dropna()\n",
    "            \n",
    "            #Call the Calssification algorithm for each of those sub_datasets with the new parameters --> Here the recursion comes in!\n",
    "            subtree = Classification(sub_data,originaldata,features,min_instances,'Y1',parent_node_class = parent_node_class)\n",
    "            \n",
    "            #Add the sub tree, grown from the sub_dataset to the tree under the root node\n",
    "            tree[best_feature][value] = subtree\n",
    "            \n",
    "        return tree   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = training_data.iloc[0:50, 87:97]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ！！！我用一个小的subset去run这个都跑不出来。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-57c6cfee5372>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Y1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-7be9d06a466c>\u001b[0m in \u001b[0;36mClassification\u001b[0;34m(data, originaldata, features, min_instances, target_attribute_name, parent_node_class)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m#Call the Calssification algorithm for each of those sub_datasets with the new parameters --> Here the recursion comes in!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0msubtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moriginaldata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_instances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Y1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparent_node_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_node_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m#Add the sub tree, grown from the sub_dataset to the tree under the root node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7be9d06a466c>\u001b[0m in \u001b[0;36mClassification\u001b[0;34m(data, originaldata, features, min_instances, target_attribute_name, parent_node_class)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m#Call the Calssification algorithm for each of those sub_datasets with the new parameters --> Here the recursion comes in!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0msubtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moriginaldata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_instances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Y1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparent_node_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_node_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m#Add the sub tree, grown from the sub_dataset to the tree under the root node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7be9d06a466c>\u001b[0m in \u001b[0;36mClassification\u001b[0;34m(data, originaldata, features, min_instances, target_attribute_name, parent_node_class)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m#Call the Calssification algorithm for each of those sub_datasets with the new parameters --> Here the recursion comes in!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0msubtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moriginaldata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_instances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Y1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparent_node_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_node_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m#Add the sub tree, grown from the sub_dataset to the tree under the root node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7be9d06a466c>\u001b[0m in \u001b[0;36mClassification\u001b[0;34m(data, originaldata, features, min_instances, target_attribute_name, parent_node_class)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m#Call the Calssification algorithm for each of those sub_datasets with the new parameters --> Here the recursion comes in!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0msubtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moriginaldata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_instances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Y1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparent_node_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_node_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m#Add the sub tree, grown from the sub_dataset to the tree under the root node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7be9d06a466c>\u001b[0m in \u001b[0;36mClassification\u001b[0;34m(data, originaldata, features, min_instances, target_attribute_name, parent_node_class)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m#Call the Calssification algorithm for each of those sub_datasets with the new parameters --> Here the recursion comes in!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0msubtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moriginaldata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_instances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Y1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparent_node_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_node_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m#Add the sub tree, grown from the sub_dataset to the tree under the root node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7be9d06a466c>\u001b[0m in \u001b[0;36mClassification\u001b[0;34m(data, originaldata, features, min_instances, target_attribute_name, parent_node_class)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m#Call the Calssification algorithm for each of those sub_datasets with the new parameters --> Here the recursion comes in!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0msubtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moriginaldata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_instances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Y1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparent_node_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_node_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m#Add the sub tree, grown from the sub_dataset to the tree under the root node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7be9d06a466c>\u001b[0m in \u001b[0;36mClassification\u001b[0;34m(data, originaldata, features, min_instances, target_attribute_name, parent_node_class)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m#Split the dataset along the value of the feature with the lowest variance and therewith create sub_datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0msub_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_feature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m#Call the Calssification algorithm for each of those sub_datasets with the new parameters --> Here the recursion comes in!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(self, cond, other, inplace, axis, level, errors, try_cast, raise_on_error)\u001b[0m\n\u001b[1;32m   6128\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6129\u001b[0m         return self._where(cond, other, inplace, axis, level,\n\u001b[0;32m-> 6130\u001b[0;31m                            errors=errors, try_cast=try_cast)\n\u001b[0m\u001b[1;32m   6131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6132\u001b[0m     @Appender(_shared_docs['where'] % dict(_shared_doc_kwargs, cond=\"False\",\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_where\u001b[0;34m(self, cond, other, inplace, axis, level, errors, try_cast)\u001b[0m\n\u001b[1;32m   5988\u001b[0m                                         \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5989\u001b[0m                                         \u001b[0mtry_cast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtry_cast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblock_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5990\u001b[0;31m                                         transpose=self._AXIS_REVERSED)\n\u001b[0m\u001b[1;32m   5991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5992\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   3430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3431\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3432\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'where'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m   3324\u001b[0m                     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_info_axis_number'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3325\u001b[0m                     kwargs[k] = obj.reindex(b_items, axis=axis,\n\u001b[0;32m-> 3326\u001b[0;31m                                             copy=align_copy)\n\u001b[0m\u001b[1;32m   3327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3328\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mgr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mPY2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2933\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2934\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2935\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2937\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reindex_axis'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3009\u001b[0m                 for axis, ax in axes.items() if ax is not None]):\n\u001b[1;32m   3010\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3011\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3012\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   4024\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4025\u001b[0m         \"\"\"\n\u001b[0;32m-> 4026\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4027\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep, mgr)\u001b[0m\n\u001b[1;32m   3658\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3659\u001b[0m                 \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3660\u001b[0;31m             \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3661\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3662\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3658\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3659\u001b[0m                 \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3660\u001b[0;31m             \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3661\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3662\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(ax)\u001b[0m\n\u001b[1;32m   3657\u001b[0m                 \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3658\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3659\u001b[0;31m                 \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3660\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3661\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mview\u001b[0;34m(self, cls)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shallow_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_shallow_copy\u001b[0;34m(self, values, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mattributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_attributes_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0mattributes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_shallow_copy_with_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_simple_new\u001b[0;34m(cls, values, name, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_identity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     _index_shared_docs['_shallow_copy'] = \"\"\"\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_reset_identity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_reset_identity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;34m\"\"\"Initializes or resets ``_id`` attribute with new object\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Identity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tree = Classification(train,train,train.columns[:-1],5,'Y1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Predict query instances\n",
    "\"\"\"\n",
    "def predict(query,tree,default = mean_data):\n",
    "    for key in list(query.keys()):\n",
    "        if key in list(tree.keys()):\n",
    "            try:\n",
    "                result = tree[key][query[key]] \n",
    "            except:\n",
    "                return default\n",
    "            result = tree[key][query[key]]\n",
    "            if isinstance(result,dict):\n",
    "                return predict(query,result)\n",
    "            else:\n",
    "                return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a training as well as a testing set\n",
    "\"\"\"\n",
    "def train_test_split(dataset):\n",
    "    training_data = dataset.iloc[:int(0.7*len(dataset))].reset_index(drop=True)#We drop the index respectively relabel the index\n",
    "    #starting form 0, because we do not want to run into errors regarding the row labels / indexes\n",
    "    testing_data = dataset.iloc[int(0.7*len(dataset)):].reset_index(drop=True)\n",
    "    return training_data,testing_data\n",
    "\n",
    "training_data = train_test_split(dataset)[0]\n",
    "testing_data = train_test_split(dataset)[1] \n",
    "\n",
    "#training_data = preprocessing.scale(training, axis = 1, copy = False)\n",
    "#testing_data = preprocessing.scale(testing, axis = 1, copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>D1</th>\n",
       "      <th>PR1</th>\n",
       "      <th>P1</th>\n",
       "      <th>F2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PR2</th>\n",
       "      <th>P2</th>\n",
       "      <th>F3</th>\n",
       "      <th>D3</th>\n",
       "      <th>...</th>\n",
       "      <th>P22</th>\n",
       "      <th>F23</th>\n",
       "      <th>D23</th>\n",
       "      <th>PR23</th>\n",
       "      <th>P23</th>\n",
       "      <th>F24</th>\n",
       "      <th>D24</th>\n",
       "      <th>PR24</th>\n",
       "      <th>P24</th>\n",
       "      <th>Y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.523705</td>\n",
       "      <td>0.714970</td>\n",
       "      <td>0.589934</td>\n",
       "      <td>3.589033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081281</td>\n",
       "      <td>32.728396</td>\n",
       "      <td>0.088096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.747756</td>\n",
       "      <td>0.166937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.590357</td>\n",
       "      <td>1.543362</td>\n",
       "      <td>0.082033</td>\n",
       "      <td>0.071894</td>\n",
       "      <td>0.391729</td>\n",
       "      <td>15.903184</td>\n",
       "      <td>4457.5098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.499391</td>\n",
       "      <td>0.681167</td>\n",
       "      <td>0.685569</td>\n",
       "      <td>3.183856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089665</td>\n",
       "      <td>32.550162</td>\n",
       "      <td>0.060542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.390423</td>\n",
       "      <td>0.288394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.636323</td>\n",
       "      <td>1.425869</td>\n",
       "      <td>0.296926</td>\n",
       "      <td>0.310715</td>\n",
       "      <td>0.501372</td>\n",
       "      <td>15.319130</td>\n",
       "      <td>5175.7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.582240</td>\n",
       "      <td>0.736953</td>\n",
       "      <td>0.777993</td>\n",
       "      <td>3.357538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085037</td>\n",
       "      <td>32.653651</td>\n",
       "      <td>0.596178</td>\n",
       "      <td>0.479989</td>\n",
       "      <td>...</td>\n",
       "      <td>8.638190</td>\n",
       "      <td>0.524757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.751154</td>\n",
       "      <td>1.335219</td>\n",
       "      <td>0.472609</td>\n",
       "      <td>0.462692</td>\n",
       "      <td>0.570540</td>\n",
       "      <td>15.272562</td>\n",
       "      <td>5954.5051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.336871</td>\n",
       "      <td>0.656440</td>\n",
       "      <td>0.504925</td>\n",
       "      <td>3.764616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081152</td>\n",
       "      <td>32.562304</td>\n",
       "      <td>0.484867</td>\n",
       "      <td>0.368219</td>\n",
       "      <td>...</td>\n",
       "      <td>7.571557</td>\n",
       "      <td>0.282719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452278</td>\n",
       "      <td>1.599185</td>\n",
       "      <td>0.212733</td>\n",
       "      <td>0.212206</td>\n",
       "      <td>0.221052</td>\n",
       "      <td>15.971122</td>\n",
       "      <td>3811.3663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.513508</td>\n",
       "      <td>0.771890</td>\n",
       "      <td>0.481677</td>\n",
       "      <td>3.623867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011132</td>\n",
       "      <td>32.631095</td>\n",
       "      <td>0.507620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.087814</td>\n",
       "      <td>0.507556</td>\n",
       "      <td>0.170087</td>\n",
       "      <td>0.591127</td>\n",
       "      <td>1.570054</td>\n",
       "      <td>0.292410</td>\n",
       "      <td>0.192269</td>\n",
       "      <td>0.456543</td>\n",
       "      <td>15.599054</td>\n",
       "      <td>4431.8269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         F1        D1       PR1        P1   F2   D2       PR2         P2  \\\n",
       "0  0.523705  0.714970  0.589934  3.589033  0.0  0.0  0.081281  32.728396   \n",
       "1  0.499391  0.681167  0.685569  3.183856  0.0  0.0  0.089665  32.550162   \n",
       "2  0.582240  0.736953  0.777993  3.357538  0.0  0.0  0.085037  32.653651   \n",
       "3  0.336871  0.656440  0.504925  3.764616  0.0  0.0  0.081152  32.562304   \n",
       "4  0.513508  0.771890  0.481677  3.623867  0.0  0.0  0.011132  32.631095   \n",
       "\n",
       "         F3        D3    ...           P22       F23       D23      PR23  \\\n",
       "0  0.088096  0.000000    ...      7.747756  0.166937  0.000000  0.590357   \n",
       "1  0.060542  0.000000    ...      8.390423  0.288394  0.000000  0.636323   \n",
       "2  0.596178  0.479989    ...      8.638190  0.524757  0.000000  0.751154   \n",
       "3  0.484867  0.368219    ...      7.571557  0.282719  0.000000  0.452278   \n",
       "4  0.507620  0.000000    ...      8.087814  0.507556  0.170087  0.591127   \n",
       "\n",
       "        P23       F24       D24      PR24        P24         Y1  \n",
       "0  1.543362  0.082033  0.071894  0.391729  15.903184  4457.5098  \n",
       "1  1.425869  0.296926  0.310715  0.501372  15.319130  5175.7999  \n",
       "2  1.335219  0.472609  0.462692  0.570540  15.272562  5954.5051  \n",
       "3  1.599185  0.212733  0.212206  0.221052  15.971122  3811.3663  \n",
       "4  1.570054  0.292410  0.192269  0.456543  15.599054  4431.8269  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute the RMSE \n",
    "\"\"\"\n",
    "def test(data,tree):\n",
    "    #Create new query instances by simply removing the target feature column from the original dataset and \n",
    "    #convert it to a dictionary\n",
    "    queries = data.iloc[:,:-1].to_dict(orient = \"records\")\n",
    "    \n",
    "    #Create a empty DataFrame in whose columns the prediction of the tree are stored\n",
    "    predicted = []\n",
    "    #Calculate the RMSE\n",
    "    for i in range(len(data)):\n",
    "        predicted.append(predict(queries[i],tree,mean_data)) \n",
    "    RMSE = np.sqrt(np.sum(((data.iloc[:,-1]-predicted)**2)/len(data)))\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-bed6696c8a4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mTrain\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPrint\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0mthe\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Y1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7be9d06a466c>\u001b[0m in \u001b[0;36mClassification\u001b[0;34m(data, originaldata, features, min_instances, target_attribute_name, parent_node_class)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mparent_node_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_attribute_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m#Select the feature which best splits the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mitem_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#Return the variance for features in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mbest_feature_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mbest_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_feature_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7be9d06a466c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mparent_node_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_attribute_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m#Select the feature which best splits the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mitem_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#Return the variance for features in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mbest_feature_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mbest_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_feature_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-e829b4ee3cdd>\u001b[0m in \u001b[0;36mvar\u001b[0;34m(data, split_attribute_name, target_name)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#If value_var = nan, we make it to be 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mvalue_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#Calculate the weighted variance of the feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/lib/type_check.py\u001b[0m in \u001b[0;36mnan_to_num\u001b[0;34m(x, copy)\u001b[0m\n\u001b[1;32m    391\u001b[0m              0.00000000e+000 +1.79769313e+308j])\n\u001b[1;32m    392\u001b[0m     \"\"\"\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m     \u001b[0mxtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train the tree, Print the tree and predict the accuracy\n",
    "\"\"\"\n",
    "tree = Classification(training_data,training_data,training_data.columns[:-1],5,'Y1')\n",
    "print(tree)\n",
    "print('#'*50)\n",
    "print('Root mean square error (RMSE): ',test(testing_data,tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a212f4a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Plot the RMSE with respect to the minimum number of instances\n",
    "\"\"\" \n",
    "fig = plt.figure()\n",
    "ax0 = fig.add_subplot(111) \n",
    "RMSE_test = []\n",
    "RMSE_train = []\n",
    "for i in range(1,100):\n",
    "    tree = Classification(training_data,training_data,training_data.columns[:-1],i,'Y1')\n",
    "    RMSE_test.append(test(testing_data,tree)) \n",
    "    RMSE_train.append(test(training_data,tree))\n",
    "   \n",
    "ax0.plot(range(1,100),RMSE_test,label='Test_Data')\n",
    "ax0.plot(range(1,100),RMSE_train,label='Train_Data')\n",
    "ax0.legend()\n",
    "ax0.set_title('RMSE with respect to the minumim number of instances per node')\n",
    "ax0.set_xlabel('#Instances')\n",
    "ax0.set_ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store 1, Category 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:,0:96]\n",
    "\n",
    "y = train.loc[:,'Y1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 96)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.iloc[:,0:96]\n",
    "\n",
    "y_test = test.loc[:,'Y1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling features\n",
    "X_scaled = preprocessing.scale(X)\n",
    "y_scaled = preprocessing.scale(y)\n",
    "\n",
    "# add a column of one to X\n",
    "# X = np.c_[np.ones(X_scaled.shape[0]),X_scaled]\n",
    "X = np.c_[np.ones(X_scaled.shape[0]),X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling features\n",
    "X_scaled_test = preprocessing.scale(X_test)\n",
    "y_scaled_test = preprocessing.scale(y_test)\n",
    "\n",
    "# add a column of one to X\n",
    "# X_test = np.c_[np.ones(X_scaled_test.shape[0]),X_scaled_test]\n",
    "X_test = np.c_[np.ones(X_scaled_test.shape[0]),X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_list, cost_list, theta_list = gradient_descent(X, y_scaled, m, theta, alpha)\n",
    "prediction_list, cost_list, theta_list = gradient_descent(X, y, m, theta, alpha)\n",
    "theta = theta_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6239804075555636"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out of sample RMSE\n",
    "pred = np.dot(X_test, theta)\n",
    "np.sqrt(((y_scaled_test - pred)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6153010650239811"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking with built-in linear regession\n",
    "lm = LinearRegression()\n",
    "\n",
    "#Fitting the model\n",
    "lm = lm.fit(X,y_scaled)\n",
    "# prediction\n",
    "pred_lm = lm.predict(X_test)\n",
    "\n",
    "# out of sample RMSE\n",
    "np.sqrt(((y_scaled_test - pred_lm)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08624320458749324\n"
     ]
    }
   ],
   "source": [
    "# compute mean sqrt difference in theta\n",
    "diff = np.sqrt(sum((theta - lm.coef_)**2))\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.93897443e-15  1.68897607e-01  6.45337934e-02 -2.22184748e-01\n",
      " -7.50181657e-01 -3.54114995e-02  7.60089058e-02 -5.90826331e-02\n",
      " -1.14606084e-01 -1.11427811e-01  1.65109148e-01  4.86166340e-02\n",
      "  3.96687487e-02  6.17830488e-02 -3.35440424e-02  1.16131742e-01\n",
      "  2.74247981e-01 -1.41022016e-01 -4.24679817e-02  1.94176429e-01\n",
      "  1.75802215e-01 -5.58335946e-02 -6.95729615e-02  5.85588941e-02\n",
      "  3.08808451e-02 -7.01114904e-02  4.11372188e-02 -2.04112791e-02\n",
      " -6.73136039e-02 -2.70766860e-02 -8.79570500e-03  1.31484674e-01\n",
      "  4.42652001e-02 -6.89768537e-02  2.91264062e-02 -3.18359483e-02\n",
      " -9.11013600e-02  1.20989645e-01 -2.12257645e-01 -1.22158400e-02\n",
      " -1.53158753e-01  3.49014645e-02  5.02360711e-02  2.40207044e-02\n",
      "  1.32087462e-01 -1.24888832e-01 -7.16961717e-02 -7.01609884e-02\n",
      " -1.74744159e-01  5.15832922e-02  1.09010905e-01 -1.71466705e-01\n",
      " -2.42149307e-01  2.99360920e-03  1.43357030e-01 -2.23451923e-02\n",
      "  9.95856908e-02  5.67061430e-02  3.66891474e-02 -2.76666681e-02\n",
      " -1.03829196e-02  5.46802665e-03 -6.50577695e-02 -5.18309527e-02\n",
      " -5.04480761e-02  6.55621463e-02 -1.48859633e-02  8.27592376e-02\n",
      "  2.23466557e-01  4.96114825e-02  1.27125843e-01  5.10038360e-02\n",
      "  3.94853255e-01 -1.15756324e-02 -4.35768856e-02  9.69171918e-02\n",
      " -4.99199188e-02 -4.96140879e-02  1.83602210e-02  7.82846662e-02\n",
      "  2.29966485e-02 -3.43809457e-02  8.24901117e-02 -6.49271613e-03\n",
      " -1.11790281e-02 -5.94065973e-02 -3.07314547e-02  4.48010519e-02\n",
      " -1.82775525e-02  1.09602825e-01  3.43065862e-03  3.89884550e-02\n",
      "  1.99244816e-01  1.56614031e-01 -1.05295978e-01  2.03258376e-01\n",
      " -7.05618096e-02]\n"
     ]
    }
   ],
   "source": [
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.70132128e-17,  1.73260702e-01,  6.41913515e-02, -2.20530473e-01,\n",
       "       -7.40478044e-01, -3.24631167e-02,  7.59545569e-02, -5.71176366e-02,\n",
       "       -1.14471849e-01, -1.22581947e-01,  1.65432064e-01,  3.52663470e-02,\n",
       "        2.12426353e-02,  6.48432995e-02, -3.75787144e-02,  1.18277469e-01,\n",
       "        2.76398326e-01, -1.32887887e-01, -4.48780271e-02,  1.89444537e-01,\n",
       "        1.75230768e-01, -6.47412842e-02, -7.10974619e-02,  7.07486863e-02,\n",
       "        3.07590029e-02, -7.48254518e-02,  3.76808475e-02, -2.24204928e-02,\n",
       "       -7.62083409e-02, -1.89763742e-02, -7.26389279e-03,  1.19114285e-01,\n",
       "        4.29040622e-02, -6.85707543e-02,  3.08103950e-02, -2.63822843e-02,\n",
       "       -8.56758234e-02,  1.19240662e-01, -2.10186846e-01, -1.65924385e-02,\n",
       "       -1.56007821e-01,  3.76040271e-02,  4.75985040e-02,  2.03521904e-02,\n",
       "        1.30071995e-01, -1.27133273e-01, -6.89461696e-02, -7.72268074e-02,\n",
       "       -1.79350082e-01,  4.13479988e-02,  1.04912747e-01, -1.96139679e-01,\n",
       "       -2.81476321e-01,  8.23218243e-03,  1.36010512e-01, -3.68458365e-02,\n",
       "        7.97658609e-02,  5.47491610e-02,  3.97041030e-02, -3.25483442e-02,\n",
       "       -1.39082466e-02,  6.37695848e-03, -6.00444885e-02, -4.37829133e-02,\n",
       "       -3.97813572e-02,  6.10600349e-02, -1.60235731e-02,  9.13346789e-02,\n",
       "        2.27737417e-01,  2.68228255e-02,  1.27077615e-01,  6.35384935e-02,\n",
       "        3.80890469e-01, -7.68264944e-03, -5.27978186e-02,  1.07764930e-01,\n",
       "       -4.48877082e-02, -4.63784938e-02,  2.00993222e-02,  7.33840181e-02,\n",
       "        2.02601015e-02, -3.01747476e-02,  8.24074167e-02, -1.41819455e-03,\n",
       "        3.86888986e-03, -7.48081064e-02, -3.30864587e-02,  4.54752289e-02,\n",
       "       -3.25639171e-02,  1.06101710e-01,  2.55712685e-03,  5.52294440e-02,\n",
       "        2.15373432e-01,  1.56908305e-01, -1.07591927e-01,  2.01185568e-01,\n",
       "       -7.22523875e-02])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store 1, Cateory 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "X = train.iloc[:,0:96]\n",
    "y = train.loc[:,'Y5']\n",
    "X_test = test.iloc[:,0:96]\n",
    "y_test = test.loc[:,'Y5']\n",
    "\n",
    "# scaling features\n",
    "X_scaled = preprocessing.scale(X)\n",
    "y_scaled = preprocessing.scale(y)\n",
    "\n",
    "#add a column of one to X\n",
    "X = np.c_[np.ones(X_scaled.shape[0]),X_scaled]\n",
    "\n",
    "# scaling features\n",
    "X_scaled_test = preprocessing.scale(X_test)\n",
    "y_scaled_test = preprocessing.scale(y_test)\n",
    "\n",
    "#add a column of one to X\n",
    "X_test = np.c_[np.ones(X_scaled_test.shape[0]),X_scaled_test]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_list, cost_list, theta_list = gradient_descent(X, y_scaled, m, theta, alpha)\n",
    "theta = theta_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6060937310386656"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out of sample RMSE\n",
    "pred = np.dot(X_test, theta)\n",
    "np.sqrt(((y_scaled_test - pred)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6070780207806457"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking with built-in linear regession\n",
    "lm = LinearRegression()\n",
    "\n",
    "#Fitting the model\n",
    "lm = lm.fit(X,y_scaled)\n",
    "# prediction\n",
    "pred_lm = lm.predict(X_test)\n",
    "\n",
    "# out of sample RMSE\n",
    "np.sqrt(((y_scaled_test - pred_lm)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08850720977520012\n"
     ]
    }
   ],
   "source": [
    "# compute mean sqrt difference in theta\n",
    "diff = np.sqrt(sum((theta - lm.coef_)**2))\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.70721526e-16  2.38328843e-02  4.61071285e-02  7.81119265e-02\n",
      "  2.19851281e-01 -2.74217012e-02 -1.74103506e-02 -1.87884846e-02\n",
      "  8.15868479e-03 -1.18182133e-01  6.84559076e-02 -3.83286403e-02\n",
      " -1.23130787e-01  8.92429321e-02 -4.22761763e-02 -8.69556435e-03\n",
      "  1.00653872e-01  3.81263096e-02 -6.93142016e-03  1.19636226e-01\n",
      " -5.70633453e-01 -1.43387686e-02  2.82941651e-02  1.49889107e-02\n",
      "  6.02694176e-02  1.50080096e-02  2.28781709e-02 -2.30607799e-02\n",
      " -6.85324707e-02  4.11112821e-02  3.57651257e-02  7.72110697e-02\n",
      "  1.40417069e-01 -8.40907604e-02  6.48370680e-02 -3.90102550e-03\n",
      "  2.36492795e-02 -4.79208355e-03 -4.74941435e-02 -8.13929463e-02\n",
      " -1.36807671e-01  3.09960550e-03 -1.88064135e-02  3.40075651e-02\n",
      "  2.29232996e-02 -1.87726640e-02 -6.35914163e-02 -7.64545094e-02\n",
      " -8.17844721e-02 -5.18746382e-02 -1.30373031e-02 -2.50839073e-01\n",
      " -2.93384171e-01 -1.93112158e-01  2.78020018e-01  6.69966286e-02\n",
      "  6.83554305e-02  6.81903172e-02 -7.08223788e-02 -1.25560821e-02\n",
      " -1.08225700e-01  1.24199835e-02 -4.54178692e-02 -8.18632761e-02\n",
      " -1.28370191e-01  5.99941785e-02  4.83148063e-02 -1.13358433e-01\n",
      " -4.75250137e-02  5.28313357e-02 -5.25012162e-02  4.04036056e-02\n",
      "  1.46363924e-01 -1.29787533e-01  7.47677150e-02  9.58350997e-02\n",
      " -2.01320115e-02 -2.75144906e-02 -3.18003766e-03  1.98001126e-02\n",
      " -2.73695891e-02  6.48605230e-02  5.40194203e-02 -8.26401143e-02\n",
      " -1.03963725e-01  1.97654420e-02  6.31174773e-02  7.81387644e-04\n",
      "  1.67424391e-02  1.21200190e-01 -4.72062242e-03 -6.04022560e-03\n",
      "  2.12833847e-02  1.87125577e-01 -4.28724975e-02 -2.51373247e-02\n",
      " -9.61487277e-02]\n"
     ]
    }
   ],
   "source": [
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.56940338e-17,  2.17208886e-02,  5.06571226e-02,  9.13596768e-02,\n",
       "        2.39064781e-01, -3.25869338e-02, -2.07709533e-02, -2.26738121e-02,\n",
       "       -4.99800773e-04, -1.16325886e-01,  6.59216767e-02, -4.86730726e-02,\n",
       "       -1.30649790e-01,  9.11802529e-02, -4.56861119e-02, -2.23522798e-02,\n",
       "        8.55375624e-02,  4.28807489e-02, -7.65845336e-03,  1.09823062e-01,\n",
       "       -5.78014170e-01, -1.89121608e-02,  3.16003611e-02,  1.61690795e-02,\n",
       "        6.03416008e-02,  1.31716034e-02,  2.35694407e-02, -1.94608521e-02,\n",
       "       -6.89968403e-02,  5.40861886e-02,  3.40690187e-02,  7.14391690e-02,\n",
       "        1.49056322e-01, -8.49940964e-02,  6.76273841e-02, -3.70407877e-03,\n",
       "        2.72932958e-02, -1.13697209e-02, -4.58570923e-02, -7.34988564e-02,\n",
       "       -1.28855295e-01,  2.55480597e-03, -2.17627313e-02,  3.67838147e-02,\n",
       "        1.97422639e-02, -1.82665457e-02, -5.32244974e-02, -7.58442875e-02,\n",
       "       -7.03897347e-02, -5.48771969e-02, -1.93842743e-02, -2.67568784e-01,\n",
       "       -3.17872113e-01, -1.87627011e-01,  2.79095903e-01,  7.22722410e-02,\n",
       "        7.71194579e-02,  7.18290578e-02, -7.02529778e-02, -2.41942361e-02,\n",
       "       -1.08021104e-01,  6.62509247e-03, -5.17574638e-02, -8.76977410e-02,\n",
       "       -1.47244536e-01,  5.53145096e-02,  4.57487293e-02, -1.05811474e-01,\n",
       "       -4.74639080e-02,  1.99454314e-02, -6.13234869e-02,  4.52743290e-02,\n",
       "        1.04374289e-01, -1.14352655e-01,  6.56829780e-02,  9.49649016e-02,\n",
       "       -1.30596636e-02, -2.65285719e-02, -3.20720077e-03,  1.58308208e-02,\n",
       "       -2.67789816e-02,  6.87361700e-02,  5.29411726e-02, -8.36796689e-02,\n",
       "       -1.10183418e-01,  8.82905025e-03,  6.85969549e-02,  1.83912985e-03,\n",
       "        5.24109027e-03,  1.19603114e-01, -5.86735735e-03, -2.07890047e-03,\n",
       "        2.36343522e-02,  1.93959890e-01, -4.76588401e-02, -3.03118119e-02,\n",
       "       -9.95784294e-02])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store 1, Category 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:,0:96]\n",
    "y = train.loc[:,'Y9']\n",
    "X_test = test.iloc[:,0:96]\n",
    "y_test = test.loc[:,'Y9']\n",
    "\n",
    "# scaling features\n",
    "X_scaled = preprocessing.scale(X)\n",
    "y_scaled = preprocessing.scale(y)\n",
    "\n",
    "#add a column of one to X\n",
    "X = np.c_[np.ones(X_scaled.shape[0]),X_scaled]\n",
    "\n",
    "# scaling features\n",
    "X_scaled_test = preprocessing.scale(X_test)\n",
    "y_scaled_test = preprocessing.scale(y_test)\n",
    "\n",
    "#add a column of one to X\n",
    "X_test = np.c_[np.ones(X_scaled_test.shape[0]),X_scaled_test]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8648267501256812"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_list, cost_list, theta_list = gradient_descent(X, y_scaled, m, theta, alpha)\n",
    "theta = theta_list[-1]\n",
    "\n",
    "# out of sample RMSE\n",
    "pred = np.dot(X_test, theta)\n",
    "np.sqrt(((y_scaled_test - pred)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8703631375067631"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking with built-in linear regession\n",
    "lm = LinearRegression()\n",
    "\n",
    "#Fitting the model\n",
    "lm = lm.fit(X,y_scaled)\n",
    "# prediction\n",
    "pred_lm = lm.predict(X_test)\n",
    "\n",
    "# out of sample RMSE\n",
    "np.sqrt(((y_scaled_test - pred_lm)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08743457722221341\n"
     ]
    }
   ],
   "source": [
    "# compute mean sqrt difference in theta\n",
    "diff = np.sqrt(sum((theta - lm.coef_)**2))\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.93667586e-15 -7.01090928e-04 -1.07618798e-01 -2.74755785e-02\n",
      " -4.36381326e-04 -1.69101659e-02 -1.15461088e-02  1.57970202e-02\n",
      " -3.54927427e-02  6.26207889e-02  1.08882815e-01 -9.64185428e-02\n",
      "  2.95842330e-02  7.63215368e-02 -1.37044315e-01  6.09299989e-02\n",
      "  7.30386591e-02 -2.13931071e-01  6.93574602e-02  1.24639223e-01\n",
      " -3.40417673e-02 -2.33787784e-02  5.55626168e-02  9.03813272e-02\n",
      "  9.11616338e-02  5.63973966e-03  3.72394791e-02  4.63845960e-02\n",
      " -1.00977401e-01 -4.24628517e-03  5.81392255e-03  2.12809625e-01\n",
      "  1.52332721e-01  1.08968130e-01  5.48812530e-02 -6.98072408e-02\n",
      " -7.03495863e-01  4.96529917e-02  1.25899877e-02 -9.45454401e-02\n",
      " -2.31358858e-03  5.13652622e-02  4.35267043e-02  2.17318827e-02\n",
      "  1.01421777e-01 -5.14678498e-03  5.16641525e-02 -7.16704695e-02\n",
      " -1.31810492e-02 -1.06549908e-01 -2.22493661e-02  1.31443323e-01\n",
      " -2.23350425e-02  3.33856614e-02  1.06511088e-01 -1.98920135e-01\n",
      " -3.25960524e-02  3.16788135e-03  3.05133140e-02 -3.05357025e-02\n",
      "  2.95815455e-02 -7.04062994e-02 -1.96910624e-02 -1.25809228e-01\n",
      " -2.25874427e-01  5.56539783e-02 -4.77640679e-02 -8.14803962e-03\n",
      " -2.15364075e-02  2.03683062e-01 -1.59297121e-02 -1.47871187e-02\n",
      "  1.98914823e-01  3.27533328e-02 -9.49105182e-02  1.01253267e-01\n",
      " -1.71002459e-02 -8.28402637e-02 -3.02284737e-02  9.15207693e-02\n",
      "  5.45162368e-02 -4.14101836e-02  5.33030393e-02 -1.52301316e-01\n",
      " -2.34304932e-01 -7.18188439e-02  8.26480256e-02  1.89517117e-02\n",
      "  4.99211094e-02  4.29027757e-02  4.19500403e-03 -6.73653447e-02\n",
      "  8.09026104e-03  1.64798365e-01  7.33297778e-02  1.55160024e-02\n",
      "  1.90196866e-01]\n"
     ]
    }
   ],
   "source": [
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.09480277e-18, -3.47296540e-03, -1.06235735e-01, -3.47421161e-02,\n",
       "       -1.27306883e-02, -1.56122412e-02, -9.22535848e-03,  1.54898323e-02,\n",
       "       -3.32307038e-02,  6.85020252e-02,  1.07422679e-01, -8.90292124e-02,\n",
       "        3.74314756e-02,  7.17682069e-02, -1.33271688e-01,  6.79198063e-02,\n",
       "        7.84546341e-02, -2.22096259e-01,  7.22292138e-02,  1.37201053e-01,\n",
       "       -2.32077852e-02, -1.59888114e-02,  5.23540287e-02,  8.43669406e-02,\n",
       "        9.18591905e-02,  1.08160293e-02,  3.61047820e-02,  4.21149378e-02,\n",
       "       -9.95265985e-02, -1.47694233e-02,  7.25201266e-03,  2.24770808e-01,\n",
       "        1.51964895e-01,  1.05546464e-01,  5.07706857e-02, -7.53193968e-02,\n",
       "       -7.14629097e-01,  5.47413216e-02,  9.81960825e-03, -9.76455691e-02,\n",
       "       -3.76376570e-03,  4.99494814e-02,  4.85976047e-02,  2.21032386e-02,\n",
       "        1.05897286e-01, -3.94451942e-03,  4.65056937e-02, -6.39255471e-02,\n",
       "       -1.16143398e-02, -1.01830612e-01, -1.62718987e-02,  1.60561925e-01,\n",
       "        1.60286110e-02,  2.96552274e-02,  1.05695020e-01, -1.98222944e-01,\n",
       "       -3.14635453e-02,  5.31176343e-03,  2.62868108e-02, -2.17019872e-02,\n",
       "        3.40591515e-02, -6.60840909e-02, -1.96951458e-02, -1.29135113e-01,\n",
       "       -2.23767079e-01,  6.34492506e-02, -4.49440289e-02, -1.97325857e-02,\n",
       "       -2.19580507e-02,  2.38084756e-01, -1.64738986e-02, -4.63429891e-02,\n",
       "        2.05867833e-01,  1.82095564e-02, -8.51667223e-02,  9.28130756e-02,\n",
       "       -2.89873597e-02, -8.68950707e-02, -2.88426135e-02,  9.79876139e-02,\n",
       "        5.67216189e-02, -4.49245320e-02,  5.25802523e-02, -1.54497083e-01,\n",
       "       -2.38145003e-01, -6.21862591e-02,  8.20781621e-02,  2.03955405e-02,\n",
       "        6.07792396e-02,  4.72241010e-02,  5.36077131e-03, -7.58256755e-02,\n",
       "        2.01082015e-03,  1.64280786e-01,  7.92671755e-02,  1.78882296e-02,\n",
       "        1.97352421e-01])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>D1</th>\n",
       "      <th>PR1</th>\n",
       "      <th>P1</th>\n",
       "      <th>F2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PR2</th>\n",
       "      <th>P2</th>\n",
       "      <th>F3</th>\n",
       "      <th>D3</th>\n",
       "      <th>...</th>\n",
       "      <th>Y18</th>\n",
       "      <th>Y19</th>\n",
       "      <th>Y20</th>\n",
       "      <th>Y21</th>\n",
       "      <th>Y22</th>\n",
       "      <th>Y23</th>\n",
       "      <th>Y24</th>\n",
       "      <th>SoupSeasonality</th>\n",
       "      <th>YogurtSeasonality</th>\n",
       "      <th>BeerSeasonality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.394231</td>\n",
       "      <td>0.642377</td>\n",
       "      <td>0.383031</td>\n",
       "      <td>3.940232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020353</td>\n",
       "      <td>36.127001</td>\n",
       "      <td>0.452300</td>\n",
       "      <td>0.223710</td>\n",
       "      <td>...</td>\n",
       "      <td>2973.6453</td>\n",
       "      <td>1003.5653</td>\n",
       "      <td>369.530</td>\n",
       "      <td>5052</td>\n",
       "      <td>82.2259</td>\n",
       "      <td>931.800</td>\n",
       "      <td>297.6946</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.540046</td>\n",
       "      <td>0.658572</td>\n",
       "      <td>0.552514</td>\n",
       "      <td>3.737499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035862</td>\n",
       "      <td>36.257655</td>\n",
       "      <td>0.468224</td>\n",
       "      <td>0.385796</td>\n",
       "      <td>...</td>\n",
       "      <td>2364.0468</td>\n",
       "      <td>1196.7563</td>\n",
       "      <td>351.427</td>\n",
       "      <td>4156</td>\n",
       "      <td>58.9798</td>\n",
       "      <td>1053.450</td>\n",
       "      <td>357.6202</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.573359</td>\n",
       "      <td>0.498220</td>\n",
       "      <td>0.652151</td>\n",
       "      <td>3.701779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019078</td>\n",
       "      <td>35.781558</td>\n",
       "      <td>0.303707</td>\n",
       "      <td>0.243862</td>\n",
       "      <td>...</td>\n",
       "      <td>1729.7132</td>\n",
       "      <td>2160.8704</td>\n",
       "      <td>341.937</td>\n",
       "      <td>3496</td>\n",
       "      <td>76.7324</td>\n",
       "      <td>950.575</td>\n",
       "      <td>325.7497</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.624476</td>\n",
       "      <td>0.613608</td>\n",
       "      <td>0.878340</td>\n",
       "      <td>3.347875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.982244</td>\n",
       "      <td>0.520920</td>\n",
       "      <td>0.396854</td>\n",
       "      <td>...</td>\n",
       "      <td>1599.0200</td>\n",
       "      <td>766.9982</td>\n",
       "      <td>392.850</td>\n",
       "      <td>3250</td>\n",
       "      <td>47.4697</td>\n",
       "      <td>1114.225</td>\n",
       "      <td>554.1446</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.547451</td>\n",
       "      <td>0.566243</td>\n",
       "      <td>0.748613</td>\n",
       "      <td>3.507515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064073</td>\n",
       "      <td>35.766705</td>\n",
       "      <td>0.232060</td>\n",
       "      <td>0.087806</td>\n",
       "      <td>...</td>\n",
       "      <td>1479.2033</td>\n",
       "      <td>994.0553</td>\n",
       "      <td>378.480</td>\n",
       "      <td>4294</td>\n",
       "      <td>50.4949</td>\n",
       "      <td>896.500</td>\n",
       "      <td>511.8459</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          F1        D1       PR1        P1   F2   D2       PR2         P2  \\\n",
       "4   0.394231  0.642377  0.383031  3.940232  0.0  0.0  0.020353  36.127001   \n",
       "6   0.540046  0.658572  0.552514  3.737499  0.0  0.0  0.035862  36.257655   \n",
       "12  0.573359  0.498220  0.652151  3.701779  0.0  0.0  0.019078  35.781558   \n",
       "14  0.624476  0.613608  0.878340  3.347875  0.0  0.0  0.000000  37.982244   \n",
       "18  0.547451  0.566243  0.748613  3.507515  0.0  0.0  0.064073  35.766705   \n",
       "\n",
       "          F3        D3       ...               Y18        Y19      Y20   Y21  \\\n",
       "4   0.452300  0.223710       ...         2973.6453  1003.5653  369.530  5052   \n",
       "6   0.468224  0.385796       ...         2364.0468  1196.7563  351.427  4156   \n",
       "12  0.303707  0.243862       ...         1729.7132  2160.8704  341.937  3496   \n",
       "14  0.520920  0.396854       ...         1599.0200   766.9982  392.850  3250   \n",
       "18  0.232060  0.087806       ...         1479.2033   994.0553  378.480  4294   \n",
       "\n",
       "        Y22       Y23       Y24  SoupSeasonality  YogurtSeasonality  \\\n",
       "4   82.2259   931.800  297.6946                1                  1   \n",
       "6   58.9798  1053.450  357.6202                1                  1   \n",
       "12  76.7324   950.575  325.7497                1                  1   \n",
       "14  47.4697  1114.225  554.1446                1                  1   \n",
       "18  50.4949   896.500  511.8459                1                  1   \n",
       "\n",
       "    BeerSeasonality  \n",
       "4                 0  \n",
       "6                 1  \n",
       "12                0  \n",
       "14                1  \n",
       "18                1  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store5 = pd.read_csv('Store5_season.csv')\n",
    "store5.head()\n",
    "\n",
    "train = store5[store5.Random == 'Train']\n",
    "test = store5[store5.Random != 'Train']\n",
    "\n",
    "# Training set\n",
    "cols = ['F1', 'D1','PR1','P1','F2', 'D2','PR2','P2', 'F3', 'D3','PR3','P3', 'F4', 'D4','PR4','P4', 'F5', 'D5','PR5','P5', 'F6', 'D6','PR6','P6', 'F7', 'D7','PR7','P7', 'F8', 'D8','PR8','P8', 'F9', 'D9','PR9','P9','F10', 'D10','PR10','P10', 'F11', 'D11','PR11','P11', 'F12', 'D12','PR12','P12', 'F13', 'D13','PR13','P13','F14', 'D14','PR14','P14', 'F15', 'D15','PR15','P15', 'F16', 'D16','PR16','P16', 'F17', 'D17','PR17','P17', 'F18', 'D18','PR18','P18', 'F19', 'D19','PR19','P19', 'F20', 'D20','PR20','P20', 'F21', 'D21','PR21','P21', 'F22', 'D22','PR22','P22', 'F23', 'D23','PR23','P23', 'F24', 'D24','PR24','P24', 'Y1','Y2','Y3','Y4','Y5','Y6','Y7','Y8','Y9', 'Y10','Y11','Y12','Y13','Y14','Y15','Y16','Y17','Y18', 'Y19','Y20','Y21','Y22','Y23','Y24','SoupSeasonality','YogurtSeasonality','BeerSeasonality']\n",
    "train = train.loc[:,cols]\n",
    "train.head()\n",
    "\n",
    "# Test set\n",
    "cols = ['F1', 'D1','PR1','P1','F2', 'D2','PR2','P2', 'F3', 'D3','PR3','P3', 'F4', 'D4','PR4','P4', 'F5', 'D5','PR5','P5', 'F6', 'D6','PR6','P6', 'F7', 'D7','PR7','P7', 'F8', 'D8','PR8','P8', 'F9', 'D9','PR9','P9','F10', 'D10','PR10','P10', 'F11', 'D11','PR11','P11', 'F12', 'D12','PR12','P12', 'F13', 'D13','PR13','P13','F14', 'D14','PR14','P14', 'F15', 'D15','PR15','P15', 'F16', 'D16','PR16','P16', 'F17', 'D17','PR17','P17', 'F18', 'D18','PR18','P18', 'F19', 'D19','PR19','P19', 'F20', 'D20','PR20','P20', 'F21', 'D21','PR21','P21', 'F22', 'D22','PR22','P22', 'F23', 'D23','PR23','P23', 'F24', 'D24','PR24','P24', 'Y1','Y2','Y3','Y4','Y5','Y6','Y7','Y8','Y9', 'Y10','Y11','Y12','Y13','Y14','Y15','Y16','Y17','Y18', 'Y19','Y20','Y21','Y22','Y23','Y24','SoupSeasonality','YogurtSeasonality','BeerSeasonality']\n",
    "test = test.loc[:,cols]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store 5, Category 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:,0:96]\n",
    "y = train.loc[:,'Y1']\n",
    "X_test = test.iloc[:,0:96]\n",
    "y_test = test.loc[:,'Y1']\n",
    "\n",
    "# scaling features\n",
    "X_scaled = preprocessing.scale(X)\n",
    "y_scaled = preprocessing.scale(y)\n",
    "\n",
    "#add a column of one to X\n",
    "X = np.c_[np.ones(X_scaled.shape[0]),X_scaled]\n",
    "\n",
    "# scaling features\n",
    "X_scaled_test = preprocessing.scale(X_test)\n",
    "y_scaled_test = preprocessing.scale(y_test)\n",
    "\n",
    "#add a column of one to X\n",
    "X_test = np.c_[np.ones(X_scaled_test.shape[0]),X_scaled_test]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6067764991336728"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_list, cost_list, theta_list = gradient_descent(X, y_scaled, m, theta, alpha)\n",
    "theta = theta_list[-1]\n",
    "\n",
    "# out of sample RMSE\n",
    "pred = np.dot(X_test, theta)\n",
    "np.sqrt(((y_scaled_test - pred)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5993405044953511"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking with built-in linear regession\n",
    "lm = LinearRegression()\n",
    "\n",
    "#Fitting the model\n",
    "lm = lm.fit(X,y_scaled)\n",
    "# prediction\n",
    "pred_lm = lm.predict(X_test)\n",
    "\n",
    "# out of sample RMSE\n",
    "np.sqrt(((y_scaled_test - pred_lm)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07021388707702521\n"
     ]
    }
   ],
   "source": [
    "# compute mean sqrt difference in theta\n",
    "diff = np.sqrt(sum((theta - lm.coef_)**2))\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.40117958e-16  5.31479893e-03  9.35531198e-02 -1.79333484e-01\n",
      " -7.78771379e-01 -8.31220249e-03  2.27997532e-02  4.55760138e-02\n",
      "  1.46822955e-01 -3.98340693e-02  1.09819461e-02 -1.33836333e-01\n",
      " -1.86692668e-01  9.42585737e-02 -1.18382693e-02 -5.50424536e-02\n",
      "  7.81033793e-02  5.53648069e-02  2.49614522e-02  9.58470708e-02\n",
      "  2.34323105e-01 -5.74663460e-02  5.43294628e-02  1.04716372e-01\n",
      "  5.88898952e-02  1.24353345e-02  8.93148220e-02  7.66986117e-02\n",
      "  1.55250046e-01 -7.54858425e-02 -6.69714328e-03 -1.05506532e-01\n",
      " -9.80993025e-02  1.11882758e-01  2.12037065e-02 -1.80786966e-02\n",
      "  1.28579820e-01  9.85298629e-02 -5.95707450e-02  8.11187687e-02\n",
      "  6.11479771e-02 -2.29696527e-02  5.42810801e-02  4.34408261e-02\n",
      "  4.73512204e-02 -7.10546669e-02  1.16181183e-02 -1.07045060e-01\n",
      " -1.92965059e-01 -5.30020619e-02  5.32900537e-02 -1.17880657e-01\n",
      " -1.98157634e-01  4.64201728e-02  3.55192648e-03  8.69231397e-03\n",
      " -1.06080104e-04 -1.58000490e-02 -7.24978811e-03 -5.03493989e-03\n",
      " -5.93416955e-02  1.28418825e-02 -2.83321525e-02  7.33520905e-04\n",
      " -1.96555911e-03 -6.05426704e-02 -2.22563447e-03  2.51441416e-02\n",
      "  3.80626124e-02  6.75782116e-02  1.32631799e-02  1.22711825e-02\n",
      "  2.28895267e-01 -9.90009033e-03 -2.56684106e-03 -2.70632328e-02\n",
      " -8.97772683e-03 -1.99838681e-02 -3.51531065e-02  5.61310990e-02\n",
      " -2.36286065e-02 -7.12849688e-02  9.39730429e-02  1.47629918e-02\n",
      "  1.93573993e-03  4.87794217e-02 -2.22486078e-02 -7.97666730e-02\n",
      " -1.34698435e-01  1.96118361e-02 -2.10289693e-03  1.43663937e-01\n",
      "  1.12888759e-01  1.15679002e-02  6.81491390e-02  7.85066160e-02\n",
      "  1.56754790e-01]\n",
      "[ 9.10483333e-17  8.75443109e-03  9.35155918e-02 -1.86136765e-01\n",
      " -7.90465215e-01 -9.93493837e-03  2.53999643e-02  4.76552604e-02\n",
      "  1.44696119e-01 -5.14142620e-02  1.20137576e-02 -1.40486566e-01\n",
      " -2.05384834e-01  9.32962918e-02 -1.33533593e-02 -5.77111815e-02\n",
      "  7.40320519e-02  5.96710634e-02  2.51515465e-02  9.68381420e-02\n",
      "  2.40700796e-01 -5.77763764e-02  5.57685464e-02  1.03118875e-01\n",
      "  5.52147806e-02  1.13173585e-02  9.37213022e-02  7.96161696e-02\n",
      "  1.60325892e-01 -7.29353439e-02 -3.55058334e-03 -1.13747703e-01\n",
      " -1.03738775e-01  1.16239642e-01  2.44682082e-02 -1.76942807e-02\n",
      "  1.34307617e-01  9.70492554e-02 -5.53848111e-02  7.51353825e-02\n",
      "  6.15855005e-02 -1.98839715e-02  5.18170762e-02  3.73054120e-02\n",
      "  4.23509442e-02 -7.17987963e-02  1.03752239e-02 -1.01823819e-01\n",
      " -1.84598994e-01 -5.30998267e-02  4.59330853e-02 -1.40192376e-01\n",
      " -2.29300401e-01  4.71138610e-02  5.76782153e-03  1.86268450e-02\n",
      "  1.21308216e-02 -1.37804827e-02 -6.78567646e-03 -5.55006823e-03\n",
      " -5.36811455e-02  2.12325302e-02 -2.83037694e-02  6.38077613e-03\n",
      "  1.36961565e-02 -5.79280838e-02  2.74140782e-03  1.96360693e-02\n",
      "  3.69255417e-02  6.20737171e-02  7.66108889e-03  6.05844053e-03\n",
      "  2.11149084e-01 -1.19205852e-02 -2.99877959e-03 -3.67604718e-02\n",
      " -2.06651928e-02 -2.32176497e-02 -3.59607643e-02  5.55514502e-02\n",
      " -2.63597416e-02 -7.20062303e-02  9.14374733e-02  2.18120567e-02\n",
      "  3.36744344e-03  4.43952120e-02 -2.17024098e-02 -7.55106531e-02\n",
      " -1.39850359e-01  2.01524306e-02 -3.91890556e-03  1.58256980e-01\n",
      "  1.31168469e-01  8.44259288e-03  6.75768162e-02  7.38538757e-02\n",
      "  1.52457667e-01]\n"
     ]
    }
   ],
   "source": [
    "print(theta)\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store 5, Category 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "X = train.iloc[:,0:96]\n",
    "y = train.loc[:,'Y5']\n",
    "X_test = test.iloc[:,0:96]\n",
    "y_test = test.loc[:,'Y5']\n",
    "\n",
    "# scaling features\n",
    "X_scaled = preprocessing.scale(X)\n",
    "y_scaled = preprocessing.scale(y)\n",
    "\n",
    "#add a column of one to X\n",
    "X = np.c_[np.ones(X_scaled.shape[0]),X_scaled]\n",
    "\n",
    "# scaling features\n",
    "X_scaled_test = preprocessing.scale(X_test)\n",
    "y_scaled_test = preprocessing.scale(y_test)\n",
    "\n",
    "#add a column of one to X\n",
    "X_test = np.c_[np.ones(X_scaled_test.shape[0]),X_scaled_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8758931112504854"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_list, cost_list, theta_list = gradient_descent(X, y_scaled, m, theta, alpha)\n",
    "theta = theta_list[-1]\n",
    "\n",
    "# out of sample RMSE\n",
    "pred = np.dot(X_test, theta)\n",
    "np.sqrt(((y_scaled_test - pred)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8738141106524364"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking with built-in linear regession\n",
    "lm = LinearRegression()\n",
    "\n",
    "#Fitting the model\n",
    "lm = lm.fit(X,y_scaled)\n",
    "# prediction\n",
    "pred_lm = lm.predict(X_test)\n",
    "\n",
    "# out of sample RMSE\n",
    "np.sqrt(((y_scaled_test - pred_lm)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0744484271204827\n"
     ]
    }
   ],
   "source": [
    "# compute mean sqrt difference in theta\n",
    "diff = np.sqrt(sum((theta - lm.coef_)**2))\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.10666411e-15 -2.64744746e-04 -7.22427676e-02  1.39461215e-02\n",
      " -5.12747400e-02 -2.02161828e-02 -3.70436573e-02  5.68208689e-02\n",
      "  9.21632534e-02  2.17343185e-02 -2.38279129e-02  3.54104089e-03\n",
      " -7.58368475e-02  4.15276563e-02 -5.82812056e-02  1.76006395e-02\n",
      "  1.64598388e-01  3.66350859e-01  9.14422435e-02 -4.03565405e-02\n",
      " -3.39497352e-01  4.77390146e-02 -7.73563589e-02 -1.10078791e-01\n",
      " -1.25637796e-01 -3.14054084e-02  2.88156634e-02 -4.53623973e-02\n",
      "  4.07978442e-03  6.91677750e-02 -1.39293233e-01 -2.74729177e-02\n",
      " -3.48571856e-02 -1.12946507e-01 -1.13151396e-01  3.41882151e-02\n",
      " -1.40324078e-02  1.68754270e-02  1.60721569e-01 -1.12467954e-01\n",
      " -1.15949104e-01  3.47878800e-04 -3.31114790e-02 -9.68991154e-03\n",
      " -7.72579349e-02  9.99744729e-02 -9.64988925e-02  9.37137192e-02\n",
      "  1.07194278e-01  8.98426584e-04 -8.64998309e-02  1.29754634e-02\n",
      "  1.06541202e-01 -1.03657282e-01  7.44398256e-02  1.72607457e-01\n",
      "  1.87104945e-02 -1.13102985e-01  5.45519439e-02  3.95078978e-02\n",
      " -1.61335492e-01  5.82115810e-02 -7.60819000e-02  8.07405342e-03\n",
      "  7.78030219e-02 -1.30820644e-01 -1.65428977e-01  4.19924181e-02\n",
      " -8.39435063e-02  6.27908396e-02  5.75822369e-02 -1.07621840e-01\n",
      "  1.15195371e-01 -2.83114667e-02  4.73722535e-02  1.61423412e-01\n",
      "  8.65101710e-02  3.20900693e-02  1.80334354e-02 -2.16104331e-02\n",
      " -8.64935052e-03  9.89932099e-02  2.83752983e-03 -3.17549814e-02\n",
      "  1.04811608e-01 -2.15705929e-02 -2.61281847e-02 -3.67428897e-02\n",
      " -8.14090763e-02  5.43825746e-02  1.29076324e-01  1.27801067e-02\n",
      "  1.07110564e-01  5.53800903e-02  8.21840577e-02 -8.89558783e-03\n",
      " -1.73797464e-02]\n",
      "[-2.94179356e-17 -2.84533120e-03 -7.42173428e-02  1.69305505e-02\n",
      " -5.08920636e-02 -1.62451585e-02 -3.61175885e-02  5.80600636e-02\n",
      "  9.84393159e-02  3.11397453e-02 -2.12749533e-02  1.01731296e-02\n",
      " -5.33614330e-02  3.88627476e-02 -5.56607354e-02  2.98035344e-02\n",
      "  1.78215402e-01  3.78215007e-01  9.65107400e-02 -6.13778189e-02\n",
      " -3.47053230e-01  4.59940791e-02 -7.71302396e-02 -1.12208908e-01\n",
      " -1.25773746e-01 -3.12852225e-02  2.69634985e-02 -5.22897047e-02\n",
      " -4.34319739e-03  6.51543865e-02 -1.45129606e-01 -1.77652128e-02\n",
      " -3.28038926e-02 -1.11728848e-01 -1.17536799e-01  3.41140209e-02\n",
      " -1.54788644e-02  2.27924918e-02  1.57035665e-01 -1.15620762e-01\n",
      " -1.20067355e-01 -1.86314567e-03 -3.12118768e-02 -7.66925090e-03\n",
      " -8.00051354e-02  1.04121696e-01 -9.29560480e-02  9.84615964e-02\n",
      "  1.16306145e-01  1.06192702e-02 -9.26697706e-02  3.73390351e-02\n",
      "  1.39430980e-01 -1.06249402e-01  7.45177085e-02  1.70189188e-01\n",
      "  1.43187924e-02 -1.12612146e-01  5.52189881e-02  3.86992887e-02\n",
      " -1.63039441e-01  5.41227923e-02 -7.69673066e-02  8.89978746e-03\n",
      "  7.58133617e-02 -1.34751679e-01 -1.67475000e-01  5.02857156e-02\n",
      " -7.99396620e-02  6.48844304e-02  5.49266983e-02 -1.26457777e-01\n",
      "  9.30283951e-02 -2.83108055e-02  5.20786187e-02  1.54291341e-01\n",
      "  8.72920420e-02  3.14136147e-02  1.64628625e-02 -2.51582782e-02\n",
      " -1.04557783e-02  1.00291773e-01  2.48930374e-03 -2.81424613e-02\n",
      "  1.13559714e-01 -2.25750915e-02 -2.91940582e-02 -3.56260925e-02\n",
      " -7.68734440e-02  5.54872320e-02  1.28325264e-01  5.46091472e-03\n",
      "  9.72221919e-02  5.31174005e-02  8.43920619e-02 -1.09943054e-02\n",
      " -2.53430676e-02]\n"
     ]
    }
   ],
   "source": [
    "print(theta)\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store 5, Cateory 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:,0:96]\n",
    "y = train.loc[:,'Y9']\n",
    "X_test = test.iloc[:,0:96]\n",
    "y_test = test.loc[:,'Y9']\n",
    "\n",
    "# scaling features\n",
    "X_scaled = preprocessing.scale(X)\n",
    "y_scaled = preprocessing.scale(y)\n",
    "\n",
    "#add a column of one to X\n",
    "X = np.c_[np.ones(X_scaled.shape[0]),X_scaled]\n",
    "\n",
    "# scaling features\n",
    "X_scaled_test = preprocessing.scale(X_test)\n",
    "y_scaled_test = preprocessing.scale(y_test)\n",
    "\n",
    "#add a column of one to X\n",
    "X_test = np.c_[np.ones(X_scaled_test.shape[0]),X_scaled_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6530624275748693"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_list, cost_list, theta_list = gradient_descent(X, y_scaled, m, theta, alpha)\n",
    "theta = theta_list[-1]\n",
    "\n",
    "# out of sample RMSE\n",
    "pred = np.dot(X_test, theta)\n",
    "np.sqrt(((y_scaled_test - pred)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6624768981360258"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking with built-in linear regession\n",
    "lm = LinearRegression()\n",
    "\n",
    "#Fitting the model\n",
    "lm = lm.fit(X,y_scaled)\n",
    "# prediction\n",
    "pred_lm = lm.predict(X_test)\n",
    "\n",
    "# out of sample RMSE\n",
    "np.sqrt(((y_scaled_test - pred_lm)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.061127403789217695\n"
     ]
    }
   ],
   "source": [
    "# compute mean sqrt difference in theta\n",
    "diff = np.sqrt(sum((theta - lm.coef_)**2))\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.17889433e-15  2.31568455e-02 -7.29758067e-02 -6.92908884e-02\n",
      " -1.68371866e-01  9.80108600e-03  7.47485407e-03  6.71029485e-02\n",
      "  1.28940627e-01  7.93471498e-02  1.15739679e-01 -1.16781065e-01\n",
      "  1.09515529e-01  8.38135692e-02 -3.82202006e-02 -1.16466911e-02\n",
      "  9.85525874e-02  1.30776196e-01  3.91407659e-02 -7.70548322e-02\n",
      "  2.86064229e-02 -4.96308734e-02  9.04329916e-03 -7.31348123e-02\n",
      " -1.52087423e-01  8.55393417e-02  9.37550960e-02  1.03514086e-01\n",
      "  1.23792484e-01  5.60916145e-02 -4.69823956e-02  7.10323040e-02\n",
      "  1.24308161e-03  1.79901201e-01  1.24210858e-01  2.73785316e-02\n",
      " -6.40426374e-01  9.24907902e-02  6.39346849e-02 -4.60965052e-02\n",
      "  4.33555425e-02 -2.15856573e-02  1.64753545e-01 -1.28217766e-01\n",
      " -4.29314034e-02  7.99049882e-02 -2.66238858e-02  3.63713712e-02\n",
      "  1.83633012e-01 -7.07277006e-02 -1.15788359e-01  1.24605942e-01\n",
      " -2.63459011e-02  5.80857534e-03 -6.08906559e-02 -3.09875375e-02\n",
      " -3.37007699e-02 -6.11167924e-02  2.10771531e-02 -1.65809984e-02\n",
      "  4.50283146e-02 -1.04664511e-01 -9.88854573e-02 -7.90766363e-02\n",
      " -2.36692972e-01 -2.14854664e-02 -2.43560521e-02 -7.80132583e-03\n",
      " -1.74341968e-02  1.37772627e-01 -6.06085365e-02  4.82097254e-02\n",
      "  1.87680716e-01  8.32286082e-02 -6.43216455e-02  7.17567650e-02\n",
      " -2.43743437e-02 -1.29476078e-02 -2.02571252e-02 -1.76948425e-02\n",
      "  1.26788297e-02  1.09618506e-02  1.46257690e-02  6.60361820e-02\n",
      " -3.62455730e-02 -1.28767032e-02 -1.70673098e-03 -3.64840144e-02\n",
      " -2.22409562e-02  7.22271388e-02 -1.02557504e-01  1.41061545e-03\n",
      "  7.58177479e-02  9.35422031e-02  1.64012928e-01 -9.33056094e-03\n",
      "  2.65581459e-01]\n",
      "[ 6.12953700e-18  2.46109303e-02 -7.14503949e-02 -7.38943595e-02\n",
      " -1.67093407e-01  8.84804131e-03  5.19014963e-03  6.46183348e-02\n",
      "  1.26704475e-01  8.39774857e-02  1.12325614e-01 -1.08696220e-01\n",
      "  1.18651571e-01  8.80180948e-02 -3.71859284e-02 -2.06821157e-02\n",
      "  9.14686842e-02  1.22357733e-01  3.62909069e-02 -6.47692218e-02\n",
      "  2.76611513e-02 -4.96440558e-02  9.36283463e-03 -7.06409546e-02\n",
      " -1.51201313e-01  8.56011254e-02  9.23197692e-02  1.07087273e-01\n",
      "  1.25557295e-01  5.86057596e-02 -4.87005268e-02  7.21739072e-02\n",
      "  3.32124475e-03  1.71969649e-01  1.20896993e-01  2.87510471e-02\n",
      " -6.49858484e-01  9.17929227e-02  6.33911671e-02 -3.06681591e-02\n",
      "  5.56990102e-02 -2.12631940e-02  1.67891685e-01 -1.27331839e-01\n",
      " -3.63001461e-02  8.22814364e-02 -3.28085056e-02  2.91345672e-02\n",
      "  1.74826916e-01 -7.99285581e-02 -1.07345663e-01  1.20464534e-01\n",
      " -3.56048812e-02  1.09621116e-02 -6.43206124e-02 -3.63258843e-02\n",
      " -3.59600860e-02 -6.16950845e-02  2.18152307e-02 -1.44637721e-02\n",
      "  4.67342374e-02 -1.11371716e-01 -9.93314219e-02 -8.73744396e-02\n",
      " -2.51802795e-01 -1.83777227e-02 -2.67500332e-02 -1.21595256e-02\n",
      " -2.13473696e-02  1.34149915e-01 -5.80403001e-02  6.93216855e-02\n",
      "  2.09050357e-01  8.45234080e-02 -6.87763876e-02  8.17402722e-02\n",
      " -1.94699983e-02 -9.44484578e-03 -1.74502389e-02 -1.58762619e-02\n",
      "  1.54704834e-02  7.60493321e-03  1.95871944e-02  5.76366329e-02\n",
      " -4.43377282e-02 -9.17806042e-03 -1.75285137e-03 -3.95604982e-02\n",
      " -2.12584512e-02  7.11366074e-02 -1.00844703e-01 -3.31203988e-03\n",
      "  7.18281422e-02  9.85672682e-02  1.66492394e-01 -5.08519745e-03\n",
      "  2.79250375e-01]\n"
     ]
    }
   ],
   "source": [
    "print(theta)\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>D1</th>\n",
       "      <th>PR1</th>\n",
       "      <th>P1</th>\n",
       "      <th>F2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PR2</th>\n",
       "      <th>P2</th>\n",
       "      <th>F3</th>\n",
       "      <th>D3</th>\n",
       "      <th>...</th>\n",
       "      <th>Y18</th>\n",
       "      <th>Y19</th>\n",
       "      <th>Y20</th>\n",
       "      <th>Y21</th>\n",
       "      <th>Y22</th>\n",
       "      <th>Y23</th>\n",
       "      <th>Y24</th>\n",
       "      <th>SoupSeasonality</th>\n",
       "      <th>YogurtSeasonality</th>\n",
       "      <th>BeerSeasonality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.579988</td>\n",
       "      <td>0.677572</td>\n",
       "      <td>0.773779</td>\n",
       "      <td>3.452738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068044</td>\n",
       "      <td>35.684569</td>\n",
       "      <td>0.558750</td>\n",
       "      <td>0.568460</td>\n",
       "      <td>...</td>\n",
       "      <td>2311.5392</td>\n",
       "      <td>1524.2188</td>\n",
       "      <td>254.137</td>\n",
       "      <td>3075</td>\n",
       "      <td>32.0537</td>\n",
       "      <td>1455.3000</td>\n",
       "      <td>398.0410</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.541984</td>\n",
       "      <td>0.667745</td>\n",
       "      <td>0.640179</td>\n",
       "      <td>3.691786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013870</td>\n",
       "      <td>35.792094</td>\n",
       "      <td>0.222313</td>\n",
       "      <td>0.267289</td>\n",
       "      <td>...</td>\n",
       "      <td>2063.1107</td>\n",
       "      <td>1692.5867</td>\n",
       "      <td>367.608</td>\n",
       "      <td>2446</td>\n",
       "      <td>34.8344</td>\n",
       "      <td>1289.7500</td>\n",
       "      <td>229.0044</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.358326</td>\n",
       "      <td>0.659058</td>\n",
       "      <td>0.687612</td>\n",
       "      <td>3.587265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014885</td>\n",
       "      <td>35.861976</td>\n",
       "      <td>0.259370</td>\n",
       "      <td>0.265203</td>\n",
       "      <td>...</td>\n",
       "      <td>2290.8526</td>\n",
       "      <td>1168.3495</td>\n",
       "      <td>333.344</td>\n",
       "      <td>2718</td>\n",
       "      <td>37.9343</td>\n",
       "      <td>1637.2250</td>\n",
       "      <td>241.6023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.497014</td>\n",
       "      <td>0.696148</td>\n",
       "      <td>0.799849</td>\n",
       "      <td>3.548171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.156589</td>\n",
       "      <td>33.586512</td>\n",
       "      <td>0.046630</td>\n",
       "      <td>0.218804</td>\n",
       "      <td>...</td>\n",
       "      <td>1045.6644</td>\n",
       "      <td>1220.1226</td>\n",
       "      <td>281.820</td>\n",
       "      <td>2475</td>\n",
       "      <td>22.1472</td>\n",
       "      <td>1405.2769</td>\n",
       "      <td>476.3977</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.500552</td>\n",
       "      <td>0.710911</td>\n",
       "      <td>0.714640</td>\n",
       "      <td>3.632497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.047256</td>\n",
       "      <td>33.639482</td>\n",
       "      <td>0.069699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1157.8470</td>\n",
       "      <td>1016.1949</td>\n",
       "      <td>314.127</td>\n",
       "      <td>3006</td>\n",
       "      <td>35.3848</td>\n",
       "      <td>1101.7271</td>\n",
       "      <td>363.4177</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          F1        D1       PR1        P1   F2  D2       PR2         P2  \\\n",
       "3   0.579988  0.677572  0.773779  3.452738  0.0   0  0.068044  35.684569   \n",
       "7   0.541984  0.667745  0.640179  3.691786  0.0   0  0.013870  35.792094   \n",
       "9   0.358326  0.659058  0.687612  3.587265  0.0   0  0.014885  35.861976   \n",
       "23  0.497014  0.696148  0.799849  3.548171  0.0   0  0.156589  33.586512   \n",
       "29  0.500552  0.710911  0.714640  3.632497  0.0   0  0.047256  33.639482   \n",
       "\n",
       "          F3        D3       ...               Y18        Y19      Y20   Y21  \\\n",
       "3   0.558750  0.568460       ...         2311.5392  1524.2188  254.137  3075   \n",
       "7   0.222313  0.267289       ...         2063.1107  1692.5867  367.608  2446   \n",
       "9   0.259370  0.265203       ...         2290.8526  1168.3495  333.344  2718   \n",
       "23  0.046630  0.218804       ...         1045.6644  1220.1226  281.820  2475   \n",
       "29  0.069699  0.000000       ...         1157.8470  1016.1949  314.127  3006   \n",
       "\n",
       "        Y22        Y23       Y24  SoupSeasonality  YogurtSeasonality  \\\n",
       "3   32.0537  1455.3000  398.0410                1                  1   \n",
       "7   34.8344  1289.7500  229.0044                1                  1   \n",
       "9   37.9343  1637.2250  241.6023                1                  1   \n",
       "23  22.1472  1405.2769  476.3977                1                  1   \n",
       "29  35.3848  1101.7271  363.4177                1                  1   \n",
       "\n",
       "    BeerSeasonality  \n",
       "3                 1  \n",
       "7                 0  \n",
       "9                 1  \n",
       "23                1  \n",
       "29                1  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store9 = pd.read_csv('Store9_season.csv')\n",
    "\n",
    "train = store9[store9.Random == 'Train']\n",
    "test = store9[store9.Random != 'Train']\n",
    "\n",
    "# Training set\n",
    "cols = ['F1', 'D1','PR1','P1','F2', 'D2','PR2','P2', 'F3', 'D3','PR3','P3', 'F4', 'D4','PR4','P4', 'F5', 'D5','PR5','P5', 'F6', 'D6','PR6','P6', 'F7', 'D7','PR7','P7', 'F8', 'D8','PR8','P8', 'F9', 'D9','PR9','P9','F10', 'D10','PR10','P10', 'F11', 'D11','PR11','P11', 'F12', 'D12','PR12','P12', 'F13', 'D13','PR13','P13','F14', 'D14','PR14','P14', 'F15', 'D15','PR15','P15', 'F16', 'D16','PR16','P16', 'F17', 'D17','PR17','P17', 'F18', 'D18','PR18','P18', 'F19', 'D19','PR19','P19', 'F20', 'D20','PR20','P20', 'F21', 'D21','PR21','P21', 'F22', 'D22','PR22','P22', 'F23', 'D23','PR23','P23', 'F24', 'D24','PR24','P24', 'Y1','Y2','Y3','Y4','Y5','Y6','Y7','Y8','Y9', 'Y10','Y11','Y12','Y13','Y14','Y15','Y16','Y17','Y18', 'Y19','Y20','Y21','Y22','Y23','Y24','SoupSeasonality','YogurtSeasonality','BeerSeasonality']\n",
    "train = train.loc[:,cols]\n",
    "train.head()\n",
    "\n",
    "# Test set\n",
    "cols = ['F1', 'D1','PR1','P1','F2', 'D2','PR2','P2', 'F3', 'D3','PR3','P3', 'F4', 'D4','PR4','P4', 'F5', 'D5','PR5','P5', 'F6', 'D6','PR6','P6', 'F7', 'D7','PR7','P7', 'F8', 'D8','PR8','P8', 'F9', 'D9','PR9','P9','F10', 'D10','PR10','P10', 'F11', 'D11','PR11','P11', 'F12', 'D12','PR12','P12', 'F13', 'D13','PR13','P13','F14', 'D14','PR14','P14', 'F15', 'D15','PR15','P15', 'F16', 'D16','PR16','P16', 'F17', 'D17','PR17','P17', 'F18', 'D18','PR18','P18', 'F19', 'D19','PR19','P19', 'F20', 'D20','PR20','P20', 'F21', 'D21','PR21','P21', 'F22', 'D22','PR22','P22', 'F23', 'D23','PR23','P23', 'F24', 'D24','PR24','P24', 'Y1','Y2','Y3','Y4','Y5','Y6','Y7','Y8','Y9', 'Y10','Y11','Y12','Y13','Y14','Y15','Y16','Y17','Y18', 'Y19','Y20','Y21','Y22','Y23','Y24','SoupSeasonality','YogurtSeasonality','BeerSeasonality']\n",
    "test = test.loc[:,cols]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store 9, Cateory 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  import sys\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X = train.iloc[:,0:96]\n",
    "y = train.loc[:,'Y1']\n",
    "X_test = test.iloc[:,0:96]\n",
    "y_test = test.loc[:,'Y1']\n",
    "\n",
    "# scaling features\n",
    "X_scaled = preprocessing.scale(X)\n",
    "y_scaled = preprocessing.scale(y)\n",
    "\n",
    "#add a column of one to X\n",
    "X = np.c_[np.ones(X_scaled.shape[0]),X_scaled]\n",
    "\n",
    "# scaling features\n",
    "X_scaled_test = preprocessing.scale(X_test)\n",
    "y_scaled_test = preprocessing.scale(y_test)\n",
    "\n",
    "#add a column of one to X\n",
    "X_test = np.c_[np.ones(X_scaled_test.shape[0]),X_scaled_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X[:,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gradient_descent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f03ad0b008c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# out of sample RMSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gradient_descent' is not defined"
     ]
    }
   ],
   "source": [
    "prediction_list, cost_list, theta_list = gradient_descent(X, y_scaled, m, theta, alpha)\n",
    "theta = theta_list[-1]\n",
    "\n",
    "# out of sample RMSE\n",
    "pred = np.dot(X_test, theta)\n",
    "np.sqrt(((y_scaled_test - pred)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7099782621106892"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking with built-in linear regession\n",
    "lm = LinearRegression()\n",
    "\n",
    "#Fitting the model\n",
    "lm = lm.fit(X,y_scaled)\n",
    "# prediction\n",
    "pred_lm = lm.predict(X_test)\n",
    "\n",
    "# out of sample RMSE\n",
    "np.sqrt(((y_scaled_test - pred_lm)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249436024317.8033\n"
     ]
    }
   ],
   "source": [
    "# compute mean sqrt difference in theta\n",
    "diff = np.sqrt(sum((theta[1:] - lm.coef_[1:])**2))\n",
    "print(diff)\n",
    "\n",
    "## may be due to the 0 entries for D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.80131573e-04,  2.80726872e-03,  1.19996067e-02,  2.41557125e-02,\n",
       "       -6.62395130e-04, -2.49436024e+11, -3.23001159e-03, -5.55261732e-03,\n",
       "        9.43372059e-03, -3.54901056e-03, -3.48732524e-03,  6.17487867e-03,\n",
       "        5.71687263e-03, -8.68654434e-04, -4.71524530e-03, -2.13922815e-03,\n",
       "       -8.17839868e-04,  2.45399130e-03, -8.33109220e-04, -7.31194804e-03,\n",
       "       -9.71780080e-04,  5.31395909e-03,  1.45723127e-03,  1.95040189e-03,\n",
       "       -4.39421807e-04, -1.51001013e-03,  3.49909785e-03, -1.55835381e-03,\n",
       "       -3.12111616e-03, -4.29659539e-03,  4.42147400e-03,  1.48818454e-03,\n",
       "       -3.87677493e-03,  7.94124599e-04, -1.60651052e-03, -3.84280788e-03,\n",
       "        8.14500814e-03, -4.27018727e-03, -6.20542882e-03, -1.58251732e-04,\n",
       "       -7.07940520e-04, -1.35727591e-03,  4.50673930e-03, -1.98933846e-03,\n",
       "       -1.52384807e-03,  2.68273403e-03,  4.85288427e-03,  1.37485309e-03,\n",
       "        3.85896471e-03, -6.50247299e-03,  1.01979344e-03, -2.90631420e-03,\n",
       "       -8.81839264e-03,  7.00916083e-03, -2.96814655e-03, -3.66433010e-03,\n",
       "       -1.44497030e-03,  1.66068010e-03,  6.39263471e-03,  3.61474334e-03,\n",
       "        6.79695452e-03, -1.75620838e-03, -9.79887867e-03, -4.87530831e-03,\n",
       "       -2.47678439e-03, -6.36074133e-04,  5.50920899e-03,  5.06184353e-04,\n",
       "        3.48969980e-03,  1.57414971e-03,  2.62702923e-02,  2.84495444e-02,\n",
       "        4.32703189e-03, -2.27232119e-03,  8.97330012e-03,  8.40035115e-03,\n",
       "        1.37628551e-03,  2.48833760e-03, -8.60743446e-04,  6.01124182e-04,\n",
       "       -1.25314560e-03, -7.42864657e-03, -8.47072664e-03, -1.76131362e-02,\n",
       "       -1.38790451e-02,  3.40506510e-03,  7.59289521e-03,  2.94944211e-03,\n",
       "       -8.61107899e-04, -1.15577425e-04, -1.16513373e-02, -1.16068377e-02,\n",
       "        8.36523856e-04,  5.74594008e-03,  2.44608395e-03,  1.00437159e-02])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta[1:] - lm.coef_[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02207648  0.08892981 -0.12798971 -0.79955942 -0.03003235  0.00747485\n",
      "  0.06166727 -0.00363802 -0.02860263  0.08109149 -0.02903149 -0.09263246\n",
      "  0.01395471  0.0265142  -0.04893331 -0.09067263 -0.02130276 -0.07693558\n",
      "  0.03249972 -0.0083648   0.01983358  0.0124093  -0.00586699 -0.0484036\n",
      "  0.06172488  0.02621521  0.01947124  0.11153216 -0.07918618 -0.03902178\n",
      " -0.02608085 -0.08681443 -0.01003942 -0.0669332  -0.03235011 -0.04165981\n",
      " -0.03166708 -0.00903284  0.07941545  0.00129133 -0.12578805  0.03963546\n",
      "  0.15112844  0.07210353 -0.07938563 -0.04089255 -0.06167544 -0.18578802\n",
      "  0.2148575  -0.06292185 -0.09854381 -0.12733411  0.06258511  0.02825989\n",
      " -0.00588258  0.04214065  0.02840504  0.01483855  0.06046215  0.02917703\n",
      " -0.00634468 -0.08069755  0.11810411  0.05662524  0.02605715  0.00255492\n",
      " -0.08407514 -0.01642344 -0.01559523 -0.0222906   0.00291672  0.05967761\n",
      " -0.06032064 -0.00813933 -0.1141308  -0.08589897  0.00410379 -0.03467826\n",
      "  0.08527321  0.05610306 -0.08835413  0.11498499 -0.01098938  0.03850488\n",
      " -0.01875423 -0.00367406 -0.02290179 -0.12946251  0.08319956 -0.04826159\n",
      "  0.02092618  0.21687755 -0.00988087  0.03537088 -0.04050169  0.04832325]\n",
      "[ 2.27566134e-02  8.61225447e-02 -1.39989320e-01 -8.23715136e-01\n",
      " -2.93699530e-02  2.49436024e+11  6.48972789e-02  1.91460087e-03\n",
      " -3.80363464e-02  8.46405029e-02 -2.55441666e-02 -9.88073349e-02\n",
      "  8.23783875e-03  2.73828506e-02 -4.42180634e-02 -8.85334015e-02\n",
      " -2.04849243e-02 -7.93895721e-02  3.33328247e-02 -1.05285645e-03\n",
      "  2.08053589e-02  7.09533691e-03 -7.32421875e-03 -5.03540039e-02\n",
      "  6.21643066e-02  2.77252197e-02  1.59721375e-02  1.13090515e-01\n",
      " -7.60650635e-02 -3.47251892e-02 -3.05023193e-02 -8.83026123e-02\n",
      " -6.16264343e-03 -6.77273273e-02 -3.07435989e-02 -3.78170013e-02\n",
      " -3.98120880e-02 -4.76264954e-03  8.56208801e-02  1.44958496e-03\n",
      " -1.25080109e-01  4.09927368e-02  1.46621704e-01  7.40928650e-02\n",
      " -7.78617859e-02 -4.35752869e-02 -6.65283203e-02 -1.87162876e-01\n",
      "  2.10998535e-01 -5.64193726e-02 -9.95635986e-02 -1.24427795e-01\n",
      "  7.14035034e-02  2.12507248e-02 -2.91442871e-03  4.58049774e-02\n",
      "  2.98500061e-02  1.31778717e-02  5.40695190e-02  2.55622864e-02\n",
      " -1.31416321e-02 -7.89413452e-02  1.27902985e-01  6.15005493e-02\n",
      "  2.85339355e-02  3.19099426e-03 -8.95843506e-02 -1.69296265e-02\n",
      " -1.90849304e-02 -2.38647461e-02 -2.33535767e-02  3.12280655e-02\n",
      " -6.46476746e-02 -5.86700439e-03 -1.23104095e-01 -9.42993164e-02\n",
      "  2.72750854e-03 -3.71665955e-02  8.61339569e-02  5.55019379e-02\n",
      " -8.71009827e-02  1.22413635e-01 -2.51865387e-03  5.61180115e-02\n",
      " -4.87518311e-03 -7.07912445e-03 -3.04946899e-02 -1.32411957e-01\n",
      "  8.40606689e-02 -4.81460094e-02  3.25775146e-02  2.28484392e-01\n",
      " -1.07173920e-02  2.96249390e-02 -4.29477692e-02  3.82795334e-02]\n"
     ]
    }
   ],
   "source": [
    "print(theta[1:])\n",
    "print(lm.coef_[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store 9, Category 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  import sys\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "X = train.iloc[:,0:96]\n",
    "y = train.loc[:,'Y5']\n",
    "X_test = test.iloc[:,0:96]\n",
    "y_test = test.loc[:,'Y5']\n",
    "\n",
    "# scaling features\n",
    "X_scaled = preprocessing.scale(X)\n",
    "y_scaled = preprocessing.scale(y)\n",
    "\n",
    "#add a column of one to X\n",
    "X = np.c_[np.ones(X_scaled.shape[0]),X_scaled]\n",
    "\n",
    "# scaling features\n",
    "X_scaled_test = preprocessing.scale(X_test)\n",
    "y_scaled_test = preprocessing.scale(y_test)\n",
    "\n",
    "#add a column of one to X\n",
    "X_test = np.c_[np.ones(X_scaled_test.shape[0]),X_scaled_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9983592580172164"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_list, cost_list, theta_list = gradient_descent(X, y_scaled, m, theta, alpha)\n",
    "theta = theta_list[-1]\n",
    "\n",
    "# out of sample RMSE\n",
    "pred = np.dot(X_test, theta)\n",
    "np.sqrt(((y_scaled_test - pred)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9985475049332176"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking with built-in linear regession\n",
    "lm = LinearRegression()\n",
    "\n",
    "#Fitting the model\n",
    "lm = lm.fit(X,y_scaled)\n",
    "# prediction\n",
    "pred_lm = lm.predict(X_test)\n",
    "\n",
    "# out of sample RMSE\n",
    "np.sqrt(((y_scaled_test - pred_lm)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3309303607045.4624\n"
     ]
    }
   ],
   "source": [
    "# compute mean sqrt difference in theta\n",
    "diff = np.sqrt(sum((theta[0:] - lm.coef_[0:])**2))\n",
    "print(diff)\n",
    "\n",
    "## similar problem as above, due to D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.64967247e-16 -3.66752650e-02  8.75497199e-02 -6.24471104e-02\n",
      " -5.27879975e-02 -5.93383493e-02  1.98062865e-01  3.76036303e-02\n",
      " -7.52592964e-02 -1.71156053e-01  1.11567614e-01 -1.76581155e-01\n",
      " -1.88272907e-01 -4.20709261e-02  1.25265399e-01 -8.84258228e-03\n",
      "  5.25298656e-02  3.17906097e-01  1.66032895e-01  7.28338207e-02\n",
      " -2.56190299e-01 -9.86199164e-02 -6.48609239e-02  2.57705543e-02\n",
      "  1.15962127e-02  1.13834841e-01 -5.34566564e-02 -5.31165264e-02\n",
      "  1.59421067e-01 -5.62198706e-03  6.50101057e-02 -6.28195456e-02\n",
      " -2.01840037e-02  1.25551816e-02 -3.31343078e-02 -2.45947842e-02\n",
      " -7.66149654e-02  3.15448268e-02  1.08381591e-01 -1.35549373e-01\n",
      "  4.08233093e-02  6.52600561e-02  4.62598844e-03  3.22173841e-02\n",
      "  6.54653498e-02  6.38873637e-03  1.25675604e-02  3.52509247e-02\n",
      "  1.33466103e-02 -1.07945634e-01  2.08575792e-01  2.20027791e-02\n",
      "  6.01288611e-02  2.36016571e-02 -4.55274955e-02  1.76738139e-01\n",
      "  1.13870233e-01 -6.57411887e-02 -4.42432604e-03 -9.36749493e-02\n",
      " -2.56583234e-01 -8.27424113e-02  9.63654712e-02  1.52156078e-01\n",
      "  1.66793552e-01 -6.71733785e-02  9.81631409e-02 -1.22654451e-01\n",
      "  4.62536870e-02  1.14237040e-01 -6.35816182e-04 -3.13355867e-01\n",
      " -1.07903517e-01 -6.13273653e-02  6.16560448e-02  4.53851101e-02\n",
      " -1.62904173e-03  4.46347341e-02 -2.40950526e-02  7.26466872e-02\n",
      "  5.98461606e-02  7.13406803e-02 -8.69369505e-02  1.46099557e-02\n",
      "  5.38251333e-02  1.66050713e-02  4.64751303e-02  1.00945973e-01\n",
      "  1.75718649e-02  1.22023709e-02 -7.79423992e-02 -9.84972603e-02\n",
      " -9.29366080e-02 -5.57584969e-02 -1.03264414e-01 -2.75326085e-02\n",
      " -2.14103612e-02]\n",
      "[-4.56654090e+07 -3.60404308e-02  8.77324887e-02 -7.16841327e-02\n",
      " -7.52002585e-02 -5.09192531e-02 -3.30930361e+12  3.48603145e-02\n",
      " -7.01865603e-02 -1.75231934e-01  1.14807129e-01 -1.74453735e-01\n",
      " -1.90618515e-01 -5.22155762e-02  1.28623962e-01  4.79125977e-03\n",
      "  6.31713867e-02  3.20800781e-01  1.59606934e-01  7.42797852e-02\n",
      " -2.50854492e-01 -1.08764648e-01 -6.97021484e-02  3.22265625e-02\n",
      "  1.23596191e-02  1.12548828e-01 -5.62133789e-02 -6.20727539e-02\n",
      "  1.55700684e-01 -4.88281250e-04  6.68640137e-02 -5.52978516e-02\n",
      " -1.18408203e-02  1.83105469e-02 -3.21044922e-02 -1.58538818e-02\n",
      " -6.41479492e-02  2.23999023e-02  1.05529785e-01 -1.33850098e-01\n",
      "  3.24707031e-02  6.57653809e-02  9.21630859e-03  2.61840820e-02\n",
      "  7.09838867e-02  1.15051270e-02  8.91113281e-03  3.07006836e-02\n",
      "  1.29585266e-02 -1.15356445e-01  2.18261719e-01  2.98461914e-02\n",
      "  7.50732422e-02  3.36914062e-02 -6.00509644e-02  1.72546387e-01\n",
      "  1.06475830e-01 -6.31103516e-02 -8.04138184e-03 -1.06048584e-01\n",
      " -2.67456055e-01 -9.27429199e-02  9.67407227e-02  1.52099609e-01\n",
      "  1.58081055e-01 -6.68945312e-02  9.79461670e-02 -1.26586914e-01\n",
      "  4.77905273e-02  1.17553711e-01 -3.84521484e-03 -3.68164062e-01\n",
      " -1.57646179e-01 -6.47277832e-02  6.64062500e-02  4.01611328e-02\n",
      " -8.17871094e-03  4.14428711e-02 -2.95410156e-02  7.09838867e-02\n",
      "  5.54962158e-02  7.72094727e-02 -7.69348145e-02  2.55279541e-02\n",
      "  8.01696777e-02  3.08837891e-02  4.52499390e-02  9.38720703e-02\n",
      "  2.12402344e-02  1.03759766e-02 -7.95783997e-02 -9.75341797e-02\n",
      " -9.80682373e-02 -5.82580566e-02 -1.05072021e-01 -2.68096924e-02\n",
      " -2.95181274e-02]\n"
     ]
    }
   ],
   "source": [
    "print(theta[0:])\n",
    "print(lm.coef_[0:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store 9, Category 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  import sys\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X = train.iloc[:,0:96]\n",
    "y = train.loc[:,'Y9']\n",
    "X_test = test.iloc[:,0:96]\n",
    "y_test = test.loc[:,'Y9']\n",
    "\n",
    "# scaling features\n",
    "X_scaled = preprocessing.scale(X)\n",
    "y_scaled = preprocessing.scale(y)\n",
    "\n",
    "#add a column of one to X\n",
    "X = np.c_[np.ones(X_scaled.shape[0]),X_scaled]\n",
    "\n",
    "# scaling features\n",
    "X_scaled_test = preprocessing.scale(X_test)\n",
    "y_scaled_test = preprocessing.scale(y_test)\n",
    "\n",
    "#add a column of one to X\n",
    "X_test = np.c_[np.ones(X_scaled_test.shape[0]),X_scaled_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6175601597670334"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_list, cost_list, theta_list = gradient_descent(X, y_scaled, m, theta, alpha)\n",
    "theta = theta_list[-1]\n",
    "\n",
    "# out of sample RMSE\n",
    "pred = np.dot(X_test, theta)\n",
    "np.sqrt(((y_scaled_test - pred)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6198805835688018"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking with built-in linear regession\n",
    "lm = LinearRegression()\n",
    "\n",
    "#Fitting the model\n",
    "lm = lm.fit(X,y_scaled)\n",
    "# prediction\n",
    "pred_lm = lm.predict(X_test)\n",
    "\n",
    "# out of sample RMSE\n",
    "np.sqrt(((y_scaled_test - pred_lm)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1157303422385.5132\n"
     ]
    }
   ],
   "source": [
    "# compute mean sqrt difference in theta\n",
    "diff = np.sqrt(sum((theta[1:] - lm.coef_[1:])**2))\n",
    "print(diff)\n",
    "\n",
    "## similar problem as above, due to D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.31750008e-02 -1.78848356e-02 -8.66322110e-02 -2.46252057e-01\n",
      "  2.51294954e-02  7.47485407e-03  1.40196969e-01  3.74572051e-02\n",
      "  4.85384085e-02  5.56925232e-02  6.82650825e-02  1.84392059e-01\n",
      " -4.84549270e-02  6.90741596e-02  6.78167625e-03  4.23836147e-02\n",
      "  5.37376707e-02 -3.30995204e-03 -8.58620059e-02 -4.10038682e-02\n",
      " -4.99884629e-02  4.82690000e-02 -2.60492530e-02 -7.06076684e-02\n",
      "  1.53751283e-02  7.88792295e-02  8.45011485e-03  7.54868160e-02\n",
      "  6.56935096e-02 -1.09207908e-02  3.44822963e-04 -3.51146364e-02\n",
      "  6.44133488e-02  6.82683542e-02 -9.50006038e-02 -8.29564499e-01\n",
      "  9.34889290e-02  6.16842853e-02 -6.98061910e-02  1.17413953e-01\n",
      " -1.08227026e-01  1.09069341e-01  8.07386428e-02  6.84826855e-02\n",
      "  8.82180265e-02  6.07008347e-02  5.95285648e-03  7.94138400e-02\n",
      " -1.51005262e-01  2.20852508e-01  1.42899615e-01  1.83660888e-01\n",
      "  2.34849852e-01 -1.63338606e-02 -1.42984485e-01  7.77263427e-02\n",
      "  1.16271256e-01 -7.64426418e-02 -5.26021222e-02  5.64358482e-03\n",
      " -8.77705782e-02  4.00111633e-02 -3.08138460e-02 -1.27843642e-01\n",
      "  6.34229528e-03  2.80697822e-02 -2.97089421e-02 -5.65468587e-02\n",
      " -1.14021999e-02 -1.16414247e-01  5.08737603e-02 -1.69040663e-01\n",
      " -4.14198719e-02  1.68005368e-02  1.32615994e-02 -1.34828456e-01\n",
      "  9.46599042e-03  6.72360383e-02 -3.93284423e-02  4.02122494e-02\n",
      "  5.75111543e-02  1.86654864e-02  7.43389316e-02  1.29809832e-01\n",
      "  2.43116099e-02 -7.82441897e-02 -1.02558726e-01 -1.13438621e-01\n",
      " -9.19441667e-03  2.17798988e-02 -3.77943059e-02 -4.57192182e-02\n",
      "  7.47258052e-03 -7.81319177e-02 -1.37188135e-02 -8.49709902e-02]\n",
      "[-2.43770480e-02 -1.80935711e-02 -8.20520269e-02 -2.42064677e-01\n",
      "  2.18129869e-02  1.15730342e+12  1.40288547e-01  3.50978699e-02\n",
      "  5.80368042e-02  5.81665039e-02  8.14208984e-02  2.12809086e-01\n",
      " -4.47998047e-02  6.84480667e-02 -3.88336182e-03  3.15170288e-02\n",
      "  5.09033203e-02 -1.73950195e-03 -8.00170898e-02 -4.13818359e-02\n",
      " -4.45098877e-02  4.77294922e-02 -3.28063965e-02 -7.27691650e-02\n",
      "  1.62963867e-02  7.83996582e-02  1.02233887e-02  7.35168457e-02\n",
      "  6.39648438e-02 -8.42285156e-03 -6.71386719e-03 -4.18395996e-02\n",
      "  6.04705811e-02  6.71119690e-02 -1.02443695e-01 -8.39416504e-01\n",
      "  9.88311768e-02  6.71844482e-02 -5.91125488e-02  1.32598877e-01\n",
      " -1.12091064e-01  1.11114502e-01  8.45031738e-02  6.88323975e-02\n",
      "  8.52203369e-02  6.37054443e-02  4.54711914e-03  7.82070160e-02\n",
      " -1.49261475e-01  2.20336914e-01  1.39251709e-01  1.79046631e-01\n",
      "  2.37503052e-01 -9.92774963e-03 -1.49330139e-01  8.13446045e-02\n",
      "  1.18728638e-01 -7.34176636e-02 -4.22897339e-02  1.75781250e-02\n",
      " -9.47418213e-02  4.08935547e-02 -3.32336426e-02 -1.36695862e-01\n",
      "  4.88281250e-03  2.68402100e-02 -3.13110352e-02 -6.46972656e-02\n",
      " -3.13720703e-02 -1.18064880e-01  7.89489746e-02 -1.70188904e-01\n",
      " -3.96575928e-02  1.80358887e-02  1.43127441e-02 -1.29760742e-01\n",
      "  1.31072998e-02  7.03582764e-02 -3.52172852e-02  4.95834351e-02\n",
      "  5.65032959e-02  1.43699646e-02  7.43818283e-02  1.24818802e-01\n",
      "  1.87988281e-02 -7.77091980e-02 -1.03408813e-01 -1.16073608e-01\n",
      " -6.53076172e-03  2.31313705e-02 -3.87878418e-02 -4.16088104e-02\n",
      "  9.63592529e-03 -8.00323486e-02 -1.65557861e-02 -8.23574066e-02]\n"
     ]
    }
   ],
   "source": [
    "print(theta[1:])\n",
    "print(lm.coef_[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters required for Gradient Descent\n",
    "alpha = 0.0001   #learning rate\n",
    "m = y.size  #no. of samples\n",
    "np.random.seed(10)\n",
    "theta = np.random.rand(97)  #initializing theta with some random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, m, theta, alpha):\n",
    "    cost_list = []   # to record all cost values to this list\n",
    "    theta_list = []  # to record all theta_0 and theta_1 values to this list \n",
    "    prediction_list = []\n",
    "    run = True\n",
    "    cost_list.append(1e10)    # we append some large value to the cost list\n",
    "    i=0\n",
    "    while run:\n",
    "        prediction = np.dot(x, theta)   # predicted y values theta_0*x0+theta_1*x1\n",
    "        prediction_list.append(prediction)\n",
    "        error = prediction - y\n",
    "        cost = 1/(2*m) * np.dot(error.T, error)   # (1/2m)*sum[(error)^2]\n",
    "        cost_list.append(cost)\n",
    "        theta = theta - (alpha * (1/m) * np.dot(x.T, error))   # alpha * (1/m) * sum[error*x]\n",
    "        theta_list.append(theta)\n",
    "        if cost_list[i]-cost_list[i+1] < 1e-9:   # checking if the change in cost function is less than 10^(-9)\n",
    "            run = False\n",
    "\n",
    "        i+=1\n",
    "    cost_list.pop(0)   # Remove the large number we added in the begining \n",
    "    return prediction_list, cost_list, theta_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.93896590e-15  1.68897530e-01  6.45338105e-02 -2.22184743e-01\n",
      " -7.50181760e-01 -3.54115516e-02  7.60088984e-02 -5.90826743e-02\n",
      " -1.14606102e-01 -1.11427657e-01  1.65109149e-01  4.86168122e-02\n",
      "  3.96689965e-02  6.17830106e-02 -3.35439873e-02  1.16131667e-01\n",
      "  2.74247907e-01 -1.41022141e-01 -4.24679446e-02  1.94176517e-01\n",
      "  1.75802245e-01 -5.58334630e-02 -6.95729273e-02  5.85587011e-02\n",
      "  3.08808364e-02 -7.01114285e-02  4.11372791e-02 -2.04112391e-02\n",
      " -6.73134653e-02 -2.70767897e-02 -8.79572395e-03  1.31484873e-01\n",
      "  4.42652491e-02 -6.89768670e-02  2.91263832e-02 -3.18360448e-02\n",
      " -9.11014548e-02  1.20989671e-01 -2.12257669e-01 -1.22157675e-02\n",
      " -1.53158686e-01  3.49014193e-02  5.02361074e-02  2.40207822e-02\n",
      "  1.32087490e-01 -1.24888809e-01 -7.16961948e-02 -7.01608577e-02\n",
      " -1.74744050e-01  5.15834223e-02  1.09010967e-01 -1.71466370e-01\n",
      " -2.42148781e-01  2.99353613e-03  1.43357135e-01 -2.23449433e-02\n",
      "  9.95860173e-02  5.67061852e-02  3.66890903e-02 -2.76666161e-02\n",
      " -1.03828625e-02  5.46801788e-03 -6.50578623e-02 -5.18310811e-02\n",
      " -5.04482522e-02  6.55622142e-02 -1.48859499e-02  8.27591102e-02\n",
      "  2.23466482e-01  4.96117786e-02  1.27125840e-01  5.10036350e-02\n",
      "  3.94853394e-01 -1.15756676e-02 -4.35767525e-02  9.69170231e-02\n",
      " -4.99199820e-02 -4.96141362e-02  1.83601999e-02  7.82847380e-02\n",
      "  2.29966974e-02 -3.43809988e-02  8.24901036e-02 -6.49280090e-03\n",
      " -1.11792802e-02 -5.94063683e-02 -3.07314007e-02  4.48010303e-02\n",
      " -1.82773504e-02  1.09602878e-01  3.43066457e-03  3.89881929e-02\n",
      "  1.99244551e-01  1.56614045e-01 -1.05295950e-01  2.03258404e-01\n",
      " -7.05617742e-02]\n"
     ]
    }
   ],
   "source": [
    "prediction_list, cost_list, theta_list = gradient_descent(X, y_scaled, m, theta, alpha)\n",
    "theta = theta_list[-1]\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCAN*PRO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "x = train.iloc[:,0:96]\n",
    "y1 = train.loc[:,'Y15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P6</th>\n",
       "      <th>P7</th>\n",
       "      <th>P8</th>\n",
       "      <th>P9</th>\n",
       "      <th>P10</th>\n",
       "      <th>...</th>\n",
       "      <th>PR21</th>\n",
       "      <th>F22</th>\n",
       "      <th>D22</th>\n",
       "      <th>PR22</th>\n",
       "      <th>F23</th>\n",
       "      <th>D23</th>\n",
       "      <th>PR23</th>\n",
       "      <th>F24</th>\n",
       "      <th>D24</th>\n",
       "      <th>PR24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.333611</td>\n",
       "      <td>3.586208</td>\n",
       "      <td>1.359563</td>\n",
       "      <td>1.073858</td>\n",
       "      <td>0.998898</td>\n",
       "      <td>-1.287972</td>\n",
       "      <td>0.119353</td>\n",
       "      <td>1.150845</td>\n",
       "      <td>1.065269</td>\n",
       "      <td>0.835635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107283</td>\n",
       "      <td>0.076177</td>\n",
       "      <td>0.462819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.698815</td>\n",
       "      <td>0.109280</td>\n",
       "      <td>0.102965</td>\n",
       "      <td>0.212245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.318235</td>\n",
       "      <td>3.591910</td>\n",
       "      <td>1.536644</td>\n",
       "      <td>1.065490</td>\n",
       "      <td>0.846866</td>\n",
       "      <td>-1.450308</td>\n",
       "      <td>0.151703</td>\n",
       "      <td>1.070809</td>\n",
       "      <td>0.973952</td>\n",
       "      <td>0.650254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.689941</td>\n",
       "      <td>0.568420</td>\n",
       "      <td>0.179579</td>\n",
       "      <td>0.654254</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.622486</td>\n",
       "      <td>0.059615</td>\n",
       "      <td>0.417307</td>\n",
       "      <td>0.182353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.234088</td>\n",
       "      <td>3.587915</td>\n",
       "      <td>1.511445</td>\n",
       "      <td>1.010953</td>\n",
       "      <td>1.026519</td>\n",
       "      <td>-1.235166</td>\n",
       "      <td>0.062039</td>\n",
       "      <td>1.037920</td>\n",
       "      <td>1.002051</td>\n",
       "      <td>0.841860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761604</td>\n",
       "      <td>0.155784</td>\n",
       "      <td>0.012299</td>\n",
       "      <td>0.296200</td>\n",
       "      <td>0.107409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.685924</td>\n",
       "      <td>0.308389</td>\n",
       "      <td>0.517745</td>\n",
       "      <td>0.438476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.354758</td>\n",
       "      <td>3.572011</td>\n",
       "      <td>1.396655</td>\n",
       "      <td>1.060190</td>\n",
       "      <td>0.760330</td>\n",
       "      <td>-1.138578</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>1.112097</td>\n",
       "      <td>1.060654</td>\n",
       "      <td>0.765085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.472342</td>\n",
       "      <td>0.013828</td>\n",
       "      <td>0.541639</td>\n",
       "      <td>0.231134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478052</td>\n",
       "      <td>0.097721</td>\n",
       "      <td>0.437889</td>\n",
       "      <td>0.333863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.263179</td>\n",
       "      <td>3.580031</td>\n",
       "      <td>1.467189</td>\n",
       "      <td>1.104332</td>\n",
       "      <td>1.030176</td>\n",
       "      <td>-1.466464</td>\n",
       "      <td>-0.043010</td>\n",
       "      <td>1.049369</td>\n",
       "      <td>0.867699</td>\n",
       "      <td>0.979412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655699</td>\n",
       "      <td>0.072487</td>\n",
       "      <td>0.010270</td>\n",
       "      <td>0.072487</td>\n",
       "      <td>0.573828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.763751</td>\n",
       "      <td>0.091464</td>\n",
       "      <td>0.468025</td>\n",
       "      <td>0.380215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         P1        P2        P3        P4        P5        P6        P7  \\\n",
       "0  1.333611  3.586208  1.359563  1.073858  0.998898 -1.287972  0.119353   \n",
       "1  1.318235  3.591910  1.536644  1.065490  0.846866 -1.450308  0.151703   \n",
       "2  1.234088  3.587915  1.511445  1.010953  1.026519 -1.235166  0.062039   \n",
       "4  1.354758  3.572011  1.396655  1.060190  0.760330 -1.138578 -0.000059   \n",
       "5  1.263179  3.580031  1.467189  1.104332  1.030176 -1.466464 -0.043010   \n",
       "\n",
       "         P8        P9       P10    ...         PR21       F22       D22  \\\n",
       "0  1.150845  1.065269  0.835635    ...     0.586353  0.000000  0.107283   \n",
       "1  1.070809  0.973952  0.650254    ...     0.689941  0.568420  0.179579   \n",
       "2  1.037920  1.002051  0.841860    ...     0.761604  0.155784  0.012299   \n",
       "4  1.112097  1.060654  0.765085    ...     0.767123  0.472342  0.013828   \n",
       "5  1.049369  0.867699  0.979412    ...     0.655699  0.072487  0.010270   \n",
       "\n",
       "       PR22       F23  D23      PR23       F24       D24      PR24  \n",
       "0  0.076177  0.462819  0.0  0.698815  0.109280  0.102965  0.212245  \n",
       "1  0.654254  0.008100  0.0  0.622486  0.059615  0.417307  0.182353  \n",
       "2  0.296200  0.107409  0.0  0.685924  0.308389  0.517745  0.438476  \n",
       "4  0.541639  0.231134  0.0  0.478052  0.097721  0.437889  0.333863  \n",
       "5  0.072487  0.573828  0.0  0.763751  0.091464  0.468025  0.380215  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_col = ['P1', 'P2','P3','P4','P5','P6','P7','P8','P9','P10','P11','P12','P13','P14','P15','P16','P17','P18','P19','P20','P21','P22','P23','P24']\n",
    "p = train.loc[:,p_col]\n",
    "ln_p = np.log(p)\n",
    "x_p = x.drop(labels = p_col, axis = 1)\n",
    "X = pd.concat([ln_p,x_p], axis = 1, join = 'outer')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# scaling features\n",
    "X_scaled = preprocessing.scale(X)\n",
    "y_scaled = preprocessing.scale(y)\n",
    "\n",
    "#add a column of one to X\n",
    "X = np.c_[np.ones(X_scaled.shape[0]),X_scaled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# test set\n",
    "x_test = test.iloc[:,0:96]\n",
    "y1_test = test.loc[:,'Y15']\n",
    "p_col = ['P1', 'P2','P3','P4','P5','P6','P7','P8','P9','P10','P11','P12','P13','P14','P15','P16','P17','P18','P19','P20','P21','P22','P23','P24']\n",
    "p_test = test.loc[:,p_col]\n",
    "ln_p_test = np.log(p_test)\n",
    "x_p_test = x_test.drop(labels = p_col, axis = 1)\n",
    "X_test = pd.concat([ln_p_test,x_p_test,], axis = 1, join = 'outer')\n",
    "X_test.head()\n",
    "\n",
    "y_test = np.log(y1_test)\n",
    "\n",
    "# scaling features\n",
    "X_scaled_test = preprocessing.scale(X_test)\n",
    "y_scaled_test = preprocessing.scale(y_test)\n",
    "\n",
    "#add a column of one to X\n",
    "X_test = np.c_[np.ones(X_scaled_test.shape[0]),X_scaled_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent\n",
    "# Parameters required for Gradient Descent\n",
    "alpha = 0.0001   #learning rate\n",
    "m = y.size  #no. of samples\n",
    "np.random.seed(10)\n",
    "theta = np.random.rand(97)  #initializing theta with some random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, m, theta, alpha):\n",
    "    cost_list = []   # to record all cost values to this list\n",
    "    theta_list = []  # to record all theta_0 and theta_1 values to this list \n",
    "    prediction_list = []\n",
    "    run = True\n",
    "    cost_list.append(1e10)    # we append some large value to the cost list\n",
    "    i=0\n",
    "    while run:\n",
    "        prediction = np.dot(x, theta)   # predicted y values theta_0*x0+theta_1*x1\n",
    "        prediction_list.append(prediction)\n",
    "        error = prediction - y\n",
    "        cost = 1/(2*m) * np.dot(error.T, error)   # (1/2m)*sum[(error)^2]\n",
    "        cost_list.append(cost)\n",
    "        theta = theta - (alpha * (1/m) * np.dot(x.T, error))   # alpha * (1/m) * sum[error*x]\n",
    "        theta_list.append(theta)\n",
    "        if cost_list[i]-cost_list[i+1] < 1e-9:   # checking if the change in cost function is less than 10^(-9)\n",
    "            run = False\n",
    "\n",
    "        i+=1\n",
    "    cost_list.pop(0)   # Remove the large number we added in the begining \n",
    "    return prediction_list, cost_list, theta_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.11752337e-16  5.54895096e-03  5.31234188e-02 -2.75746295e-01\n",
      " -1.56497052e-02 -5.78234325e-02 -5.14717387e-02  1.76986242e-01\n",
      " -1.04426180e-01 -1.73586551e-02  3.87254661e-02  4.35027517e-02\n",
      " -1.01470522e-01  4.02066332e-02 -1.08375885e-02 -6.46459823e-01\n",
      "  3.68861002e-02 -6.16174282e-02  1.02142060e-01  6.20457752e-02\n",
      " -6.45951467e-02  5.98543639e-02  1.07165618e-02 -6.73143321e-02\n",
      "  3.42141673e-02  1.52937894e-03 -3.22617123e-02  4.67928835e-03\n",
      "  1.55607120e-02  6.01038953e-01  2.81041574e-02 -2.45722251e-01\n",
      "  8.63367775e-02 -7.72462342e-02 -3.80813400e-02  2.27385299e-02\n",
      "  5.40984183e-02 -2.11112405e-02  3.52979523e-02 -7.87309717e-02\n",
      "  2.70698080e-02  2.14813394e-04  1.02223552e-02  7.68271498e-02\n",
      "  8.20103349e-02  5.96907325e-02 -1.29683109e-01  4.16269642e-02\n",
      " -2.27682521e-02  9.65574680e-02 -1.07803710e-02  2.15590646e-02\n",
      " -5.07001635e-02  9.76361184e-03  1.68498554e-02 -2.60572852e-02\n",
      " -1.22613932e-02  7.30289718e-02 -4.24879739e-04  1.04301698e-02\n",
      " -5.18695453e-02  1.47185675e-01  1.10748789e-02  2.40799461e-02\n",
      "  6.05099239e-02 -3.41145838e-02 -1.46167110e-02  2.86108058e-02\n",
      "  2.15708521e-01  9.17728281e-02  1.24687949e-02  3.92088447e-02\n",
      "  3.41087764e-02 -9.20966637e-04 -1.90062530e-02 -8.69533433e-02\n",
      "  1.41369830e-01 -9.87251078e-02  1.67804312e-03 -3.25666848e-02\n",
      "  1.03367319e-01  7.37953230e-02  1.00085188e-01 -7.18156304e-03\n",
      "  4.51704280e-03  5.22345544e-03  9.34275457e-02  2.41264589e-02\n",
      " -5.13239544e-03  1.96957875e-02  9.18516674e-02  1.04705302e-02\n",
      "  6.53010803e-02 -7.37156140e-02  6.06774113e-02  4.03486684e-02\n",
      "  7.14847516e-02]\n"
     ]
    }
   ],
   "source": [
    "prediction_list, cost_list, theta_list = gradient_descent(X, y_scaled, m, theta, alpha)\n",
    "theta = theta_list[-1]\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7779227200171015"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out of sample RMSE\n",
    "pred = np.dot(X_test, theta)\n",
    "np.sqrt(((y_scaled_test - pred)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7757133142684093"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking with built-in linear regession\n",
    "lm = LinearRegression()\n",
    "\n",
    "#Fitting the model\n",
    "lm = lm.fit(X,y_scaled)\n",
    "# prediction\n",
    "pred_lm = lm.predict(X_test)\n",
    "\n",
    "# out of sample RMSE\n",
    "np.sqrt(((y_scaled_test - pred_lm)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07754010914968144\n"
     ]
    }
   ],
   "source": [
    "# compute mean sqrt difference in theta\n",
    "diff = np.sqrt(sum((theta[30:] - lm.coef_[30:])**2))\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.54895096e-03  5.31234188e-02 -2.75746295e-01 -1.56497052e-02\n",
      " -5.78234325e-02 -5.14717387e-02  1.76986242e-01 -1.04426180e-01\n",
      " -1.73586551e-02  3.87254661e-02  4.35027517e-02 -1.01470522e-01\n",
      "  4.02066332e-02 -1.08375885e-02 -6.46459823e-01  3.68861002e-02\n",
      " -6.16174282e-02  1.02142060e-01  6.20457752e-02 -6.45951467e-02\n",
      "  5.98543639e-02  1.07165618e-02 -6.73143321e-02  3.42141673e-02\n",
      "  1.52937894e-03 -3.22617123e-02  4.67928835e-03  1.55607120e-02\n",
      "  6.01038953e-01  2.81041574e-02 -2.45722251e-01  8.63367775e-02\n",
      " -7.72462342e-02 -3.80813400e-02  2.27385299e-02  5.40984183e-02\n",
      " -2.11112405e-02  3.52979523e-02 -7.87309717e-02  2.70698080e-02\n",
      "  2.14813394e-04  1.02223552e-02  7.68271498e-02  8.20103349e-02\n",
      "  5.96907325e-02 -1.29683109e-01  4.16269642e-02 -2.27682521e-02\n",
      "  9.65574680e-02 -1.07803710e-02  2.15590646e-02 -5.07001635e-02\n",
      "  9.76361184e-03  1.68498554e-02 -2.60572852e-02 -1.22613932e-02\n",
      "  7.30289718e-02 -4.24879739e-04  1.04301698e-02 -5.18695453e-02\n",
      "  1.47185675e-01  1.10748789e-02  2.40799461e-02  6.05099239e-02\n",
      " -3.41145838e-02 -1.46167110e-02  2.86108058e-02  2.15708521e-01\n",
      "  9.17728281e-02  1.24687949e-02  3.92088447e-02  3.41087764e-02\n",
      " -9.20966637e-04 -1.90062530e-02 -8.69533433e-02  1.41369830e-01\n",
      " -9.87251078e-02  1.67804312e-03 -3.25666848e-02  1.03367319e-01\n",
      "  7.37953230e-02  1.00085188e-01 -7.18156304e-03  4.51704280e-03\n",
      "  5.22345544e-03  9.34275457e-02  2.41264589e-02 -5.13239544e-03\n",
      "  1.96957875e-02  9.18516674e-02  1.04705302e-02  6.53010803e-02\n",
      " -7.37156140e-02  6.06774113e-02  4.03486684e-02  7.14847516e-02]\n",
      "[-1.03710423e-02  5.94494644e-02 -2.79496496e-01 -8.13431155e-03\n",
      " -5.18064921e-02 -4.79051257e-02  1.74285564e-01 -9.16721458e-02\n",
      " -7.95157532e-03  3.61795204e-02  5.25648048e-02 -1.02588174e-01\n",
      "  6.48057053e-02 -1.45277013e-02 -6.58784535e-01  2.28576464e-02\n",
      " -5.88172332e-02  5.28089660e-02  5.92397005e-02 -6.77772456e-02\n",
      "  8.23201263e-02  1.64855387e-02 -8.11438508e-02  2.56725480e-02\n",
      " -1.73663707e-03 -3.03388596e-02  1.49557538e-03  2.80588136e-02\n",
      " -1.07912559e+13  2.35059993e-02 -2.50701305e-01  8.64772129e-02\n",
      " -7.37976032e-02 -4.69834061e-02  2.80144215e-02  6.34061850e-02\n",
      " -1.80439184e-02  2.93937636e-02 -7.74532888e-02  1.74509729e-02\n",
      " -3.93877025e-03  1.60012525e-02  8.02542198e-02  7.87440685e-02\n",
      "  5.02875193e-02 -1.26452320e-01  3.90237273e-02 -7.18920488e-03\n",
      "  1.02771499e-01 -9.93321727e-03  2.91401741e-02 -5.61204852e-02\n",
      "  7.15602245e-03  1.96020901e-02 -2.69678030e-02 -5.19122475e-03\n",
      "  7.28895482e-02  2.13721445e-03  8.36248631e-03 -5.23225874e-02\n",
      "  1.43321065e-01  2.61974263e-02  3.42683903e-02  7.98409163e-02\n",
      " -5.41542635e-02 -1.82522347e-02  3.15933065e-02  2.15094197e-01\n",
      "  7.82900754e-02  2.70658439e-03  3.74414479e-02  3.00710349e-02\n",
      " -3.64278294e-04 -1.70596228e-02 -9.13970570e-02  1.46871648e-01\n",
      " -1.05209371e-01 -5.24528191e-02 -3.61345641e-02  1.11118010e-01\n",
      "  6.84667766e-02  9.53774251e-02 -1.15872731e-02  1.59604138e-03\n",
      "  1.17743094e-02  1.01308743e-01  3.29788222e-02  3.94526379e-03\n",
      "  2.04711006e-02  8.80431638e-02  8.05193850e-03  6.26924871e-02\n",
      " -8.21887791e-02  5.71683894e-02  4.08579885e-02  7.26656045e-02]\n"
     ]
    }
   ],
   "source": [
    "print(theta[1:])\n",
    "print(lm.coef_[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear-logit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "X = train.iloc[:,0:96]\n",
    "y1 = train.loc[:,'Y2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "M = 1.5*np.max(y1)\n",
    "y = y1/(M-y1)\n",
    "\n",
    "# scaling features\n",
    "X_scaled = preprocessing.scale(X)\n",
    "y_scaled = preprocessing.scale(y)\n",
    "\n",
    "#add a column of one to X\n",
    "X = np.c_[np.ones(X_scaled.shape[0]),X_scaled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 97)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# test set\n",
    "X_test = test.iloc[:,0:96]\n",
    "y1_test = test.loc[:,'Y2']\n",
    "\n",
    "M_test = 1.5*np.max(y1_test)\n",
    "y_test = y1_test/(M-y1_test)\n",
    "\n",
    "# scaling features\n",
    "X_scaled_test = preprocessing.scale(X_test)\n",
    "y_scaled_test = preprocessing.scale(y_test)\n",
    "\n",
    "#add a column of one to X\n",
    "X_test = np.c_[np.ones(X_scaled_test.shape[0]),X_scaled_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent\n",
    "# Parameters required for Gradient Descent\n",
    "alpha = 0.0001   #learning rate\n",
    "m = y.size  #no. of samples\n",
    "np.random.seed(10)\n",
    "theta = np.random.rand(97)  #initializing theta with some random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.50374456e-18  6.10661316e-02 -3.65336744e-02 -7.01220143e-02\n",
      " -5.36484849e-02 -9.51782118e-02  1.98062865e-01  1.79607449e-01\n",
      " -3.39464003e-01 -2.42167982e-02 -2.54291662e-03  1.19390336e-02\n",
      "  1.82412567e-02  4.04942591e-02 -1.70252394e-01  1.00433026e-02\n",
      " -5.65158237e-02 -1.25558597e-02  8.34072080e-02 -8.38000719e-02\n",
      " -8.88583433e-02 -7.37410577e-02 -1.67284915e-02 -1.92746140e-02\n",
      " -5.85995971e-02 -5.36181439e-02  5.49410563e-02  1.39263742e-01\n",
      "  1.53933507e-01 -1.02195504e-02  4.41994480e-03 -2.40502941e-03\n",
      " -5.78154786e-02 -2.66232858e-02  1.33662728e-02 -4.13871376e-02\n",
      "  1.24153646e-02  9.02605750e-02  1.39793958e-02 -6.76906037e-03\n",
      "  6.09954295e-02  1.64998993e-01 -1.03705265e-01 -1.10463412e-01\n",
      "  4.40385912e-02 -6.67409265e-02 -3.75953128e-03 -1.10591924e-01\n",
      " -3.62867210e-02 -1.25851919e-01  8.70553258e-02 -1.52564573e-01\n",
      " -2.11413094e-01  3.66362335e-02  1.17008473e-01  9.39267178e-03\n",
      "  1.43662038e-01  1.44420565e-01 -1.92948100e-01 -9.76352069e-02\n",
      " -1.89373870e-01  1.39914981e-01 -5.75873926e-02 -8.06558768e-02\n",
      " -2.31035884e-03 -4.15825348e-02  1.97030868e-02  3.04230422e-02\n",
      "  4.09408702e-02 -3.43863162e-01 -1.04853047e-01  2.51494014e-01\n",
      " -1.99286645e-01  1.41120497e-02 -5.18091229e-02 -2.49314479e-02\n",
      " -1.95680050e-01 -1.39790475e-02  1.57975224e-01 -2.08362250e-02\n",
      "  7.24841148e-02 -1.00815366e-01 -2.26278696e-02 -3.52103937e-02\n",
      " -2.07729320e-01 -1.31490535e-01 -9.43807899e-02  9.59685699e-02\n",
      " -1.18910133e-01  1.85590727e-02 -3.96982137e-02  4.21122146e-02\n",
      "  5.96323242e-02 -1.36904448e-01 -1.08170273e-01  8.09736377e-03\n",
      " -9.89593147e-02]\n"
     ]
    }
   ],
   "source": [
    "prediction_list, cost_list, theta_list = gradient_descent(X, y_scaled, m, theta, alpha)\n",
    "theta = theta_list[-1]\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6553186586487223"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out of sample RMSE\n",
    "pred = np.dot(X_test, theta)\n",
    "np.sqrt(((y_scaled_test - pred)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6566290314177038"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking with built-in linear regession\n",
    "lm = LinearRegression()\n",
    "\n",
    "#Fitting the model\n",
    "lm = lm.fit(X,y_scaled)\n",
    "# prediction\n",
    "pred_lm = lm.predict(X_test)\n",
    "\n",
    "# out of sample RMSE\n",
    "np.sqrt(((y_scaled_test - pred_lm)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06257437109826537\n"
     ]
    }
   ],
   "source": [
    "# compute mean sqrt difference in theta\n",
    "diff = np.sqrt(sum((theta[8:] - lm.coef_[8:])**2))\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.50374456e-18  6.10661316e-02 -3.65336744e-02 -7.01220143e-02\n",
      " -5.36484849e-02 -9.51782118e-02  1.98062865e-01  1.79607449e-01\n",
      " -3.39464003e-01 -2.42167982e-02 -2.54291662e-03  1.19390336e-02\n",
      "  1.82412567e-02  4.04942591e-02 -1.70252394e-01  1.00433026e-02\n",
      " -5.65158237e-02 -1.25558597e-02  8.34072080e-02 -8.38000719e-02\n",
      " -8.88583433e-02 -7.37410577e-02 -1.67284915e-02 -1.92746140e-02\n",
      " -5.85995971e-02 -5.36181439e-02  5.49410563e-02  1.39263742e-01\n",
      "  1.53933507e-01 -1.02195504e-02  4.41994480e-03 -2.40502941e-03\n",
      " -5.78154786e-02 -2.66232858e-02  1.33662728e-02 -4.13871376e-02\n",
      "  1.24153646e-02  9.02605750e-02  1.39793958e-02 -6.76906037e-03\n",
      "  6.09954295e-02  1.64998993e-01 -1.03705265e-01 -1.10463412e-01\n",
      "  4.40385912e-02 -6.67409265e-02 -3.75953128e-03 -1.10591924e-01\n",
      " -3.62867210e-02 -1.25851919e-01  8.70553258e-02 -1.52564573e-01\n",
      " -2.11413094e-01  3.66362335e-02  1.17008473e-01  9.39267178e-03\n",
      "  1.43662038e-01  1.44420565e-01 -1.92948100e-01 -9.76352069e-02\n",
      " -1.89373870e-01  1.39914981e-01 -5.75873926e-02 -8.06558768e-02\n",
      " -2.31035884e-03 -4.15825348e-02  1.97030868e-02  3.04230422e-02\n",
      "  4.09408702e-02 -3.43863162e-01 -1.04853047e-01  2.51494014e-01\n",
      " -1.99286645e-01  1.41120497e-02 -5.18091229e-02 -2.49314479e-02\n",
      " -1.95680050e-01 -1.39790475e-02  1.57975224e-01 -2.08362250e-02\n",
      "  7.24841148e-02 -1.00815366e-01 -2.26278696e-02 -3.52103937e-02\n",
      " -2.07729320e-01 -1.31490535e-01 -9.43807899e-02  9.59685699e-02\n",
      " -1.18910133e-01  1.85590727e-02 -3.96982137e-02  4.21122146e-02\n",
      "  5.96323242e-02 -1.36904448e-01 -1.08170273e-01  8.09736377e-03\n",
      " -9.89593147e-02]\n",
      "[ 7.63760690e+07  6.47399672e-02 -4.06781535e-02 -8.10326287e-02\n",
      " -7.10346550e-02 -9.90518731e-02  5.53485902e+12  1.77732907e-01\n",
      " -3.44546825e-01 -2.11181641e-02 -4.88281250e-04  2.03552246e-02\n",
      "  2.97737122e-02  3.89556885e-02 -1.70066833e-01  1.12609863e-02\n",
      " -5.41992188e-02 -1.03759766e-02  8.47778320e-02 -8.37402344e-02\n",
      " -8.66699219e-02 -7.21435547e-02 -2.01416016e-02 -2.22167969e-02\n",
      " -6.37817383e-02 -5.90820312e-02  5.63964844e-02  1.45996094e-01\n",
      "  1.56677246e-01 -8.54492188e-03  5.98144531e-03 -9.52148438e-03\n",
      " -6.10351562e-02 -2.49023438e-02  1.32446289e-02 -3.46679688e-02\n",
      "  2.31933594e-02  8.35571289e-02  1.40380859e-02 -1.25732422e-02\n",
      "  4.58374023e-02  1.71325684e-01 -1.04125977e-01 -1.18041992e-01\n",
      "  4.23583984e-02 -6.32324219e-02 -4.15039062e-03 -1.16455078e-01\n",
      " -3.06854248e-02 -1.40014648e-01  8.20312500e-02 -1.66748047e-01\n",
      " -2.43652344e-01  3.16162109e-02  1.24313354e-01  4.30297852e-03\n",
      "  1.41479492e-01  1.41479492e-01 -1.93847656e-01 -1.02416992e-01\n",
      " -1.94213867e-01  1.31225586e-01 -5.29785156e-02 -7.44628906e-02\n",
      " -2.44140625e-04 -4.11376953e-02  1.78527832e-02  2.70996094e-02\n",
      "  3.64990234e-02 -3.60839844e-01 -1.03485107e-01  2.60009766e-01\n",
      " -2.06878662e-01  1.21459961e-02 -5.56640625e-02 -2.39257812e-02\n",
      " -1.96289062e-01 -1.26342773e-02  1.60705566e-01 -2.05078125e-02\n",
      "  7.03430176e-02 -9.91821289e-02 -1.79443359e-02 -2.97698975e-02\n",
      " -1.97364807e-01 -1.24511719e-01 -9.66644287e-02  8.63037109e-02\n",
      " -1.24267578e-01  1.60522461e-02 -4.06723022e-02  5.24902344e-02\n",
      "  6.71997070e-02 -1.34826660e-01 -1.12121582e-01  5.00488281e-03\n",
      " -9.82666016e-02]\n"
     ]
    }
   ],
   "source": [
    "print(theta)\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1273965976066281\n"
     ]
    }
   ],
   "source": [
    "diff = np.sqrt(sum((theta[1:] - coef[1:])**2))\n",
    "print(diff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
